<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[异步编排CompletebleFuture]]></title>
    <url>%2F2019%2F11%2F26%2F%E5%BC%82%E6%AD%A5%E7%BC%96%E6%8E%92CompletableFuture%2F</url>
    <content type="text"><![CDATA[特点在传统future上，只能异步调用get方法，获取计算结果，能做的事情十分有限，比如想要异步执行完任务之后再去执行另一个任务。传统future做这个事情就显得力不从心了。这就是CompletebleFuture解决的问题。CompletebleFuture提供了丰富的接口用来添加异步任务的回调函数。 简单使用创建异步任务创建异步任务主要有以下三种 1CompletableFuture.supplyAsync(Supplier&lt;U&gt; supplier) 1CompletableFuture.runAsync(Runnable runnable) 12345CompletableFuture&lt;Object&gt; future=new CompletableFuture&lt;&gt;();new Thread(()-&gt;&#123; Object o=getO(); future.complete(o);&#125;).start(); 添加回调函数1thenAccept(Consumer&lt;? super T&gt; action) 消费异步任务结果回调函数传入参数是一个 Consumer 1thenCompose(Function&lt;? super T, ? extends CompletionStage&lt;U&gt;&gt; fn) 同过上一个异步任务的结果 转换为下个异步任务对象 1thenApply(Function&lt;? super T,? extends U&gt; fn) 对异步任务的结果进行转换 12thenCombine(CompletionStage&lt;? extends U&gt; other, BiFunction&lt;? super T,? super U,? extends V&gt; fn) 组合当前异步任务和另一个异步任务（other）的结果。 1thenRun(Runnable action) 异步任务完成后的回调函数 123thenAcceptBoth( CompletionStage&lt;? extends U&gt; other, BiConsumer&lt;? super T, ? super U&gt; action) 当两个异步任务都完成回调消费函数 12acceptEither( CompletionStage&lt;? extends T&gt; other, Consumer&lt;? super T&gt; action) 当两个异步任务的一个完成时 回调消费函数 12runAfterBoth(CompletionStage&lt;?&gt; other, Runnable action) 当两个任务完成时 回调action 12runAfterEither(CompletionStage&lt;?&gt; other, Runnable action) 当两个异步任务的一个完成时 回调action 上面的函数都有一个异步版本 *Async（）可以自己传入线程池，默认为ForkJoinPool.commonPool() 还有两个重要的回调函数 当完成时回调 a12whenComplete( BiConsumer&lt;? super T, ? super Throwable&gt; action 抛出异常时回调 1234exceptionally( Function&lt;Throwable, ? extends T&gt; fn) &#123; return uniExceptionallyStage(fn);&#125; 这两个函数有一个地方需要注意以下，使用whenComplete时，如果在异步任务中有异常抛出，在异步转同步的时候同样会抛出异常，而使用了exceptionally，在异步转同步的时候不会抛出异常。 注意2点 否则出了异常情况下调试起来很麻烦： 这里如果没有在exceptionally 中打出异常堆栈，转同步的时候，也不会抛异常，异步任务没有正常执行的的信息就会被吃掉。 没有调用转同步方法,也没有使用exceptionally ，异常信息也会被吃掉。 异步转同步get（） 阻塞直到获取任务结果，或者超时， 可以设置超时时间，抛出受检查异常， join（）阻塞直到获取任务结果，不抛出受检查异常 除了通过get，join来同步任务以外还可以通过下面两个方法 12CompletableFuture.allOf(CompletableFuture&lt;?&gt;... cfs).join()//阻塞直到所有任务完成CompletableFuture.anyOf(CompletableFuture&lt;?&gt;... cfs).join()//阻塞直到任一个任务完成 示例123456789101112List&lt;CompletableFuture&lt;IndicatorResultEntity&gt;&gt; futures = resultModelList.stream().map(x -&gt; CompletableFuture.supplyAsync(() -&gt; &#123; return doSomething(); &#125;, executorService)thenApply(x-&gt;&#123; return doSomething(x) &#125;).exceptionally(e -&gt; &#123; IndicatorResultEntity resultEntity = new IndicatorResultEntity(); log.error("计算指标出错：&#123;&#125;", resultEntity.getExpressionStatement(), e); return resultEntity; &#125;)).collect(Collectors.toList());#等待所有任务完成CompletableFuture.anyOf(futures.stream().toArray(size -&gt; new CompletableFuture[size])).join();]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>CompletebleFuture</tag>
        <tag>异步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql死锁问题记录]]></title>
    <url>%2F2019%2F10%2F30%2Fmysql%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录一下工作中遇到的mysql死锁问题，防止后面再踩坑。 #多索引多线程更新发生死锁 问题描述数据库索引是这样的 多线程执行的sql 是这样的 update indicator set result=&#39;1&#39; where fk_indicator_id=? and fk_indicator_report_id =? 然后就发生了死锁 分析 通过一番搜索读大佬们的博客发现 update时，如果where条件里面涉及多个字段，且字段都分别建了索引的话，mysql会多个索引各走一遍，然后结果取个交集；mysql会使用index merge 优化使得有可能加锁的顺序不一致，导致相互等待，导致死锁。 解决建立 两个字段的联合索引]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>死锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java程序优雅的退出]]></title>
    <url>%2F2019%2F10%2F11%2FJava%E7%A8%8B%E5%BA%8F%E4%BC%98%E9%9B%85%E7%9A%84%E9%80%80%E5%87%BA%2F</url>
    <content type="text"><![CDATA[背景最近收到一个新需求，需要充kafka队列中那消息解析写到es中。要求不能漏写数据，或者重复写数据。‘ 问题如果程序中途需要手动停止，就需要把已经从kafka中拿到的数据，写进了es 才能停止程序。否则就会漏写数据或者重复写入数据 解决钩子函数ShutdownHook只是一个已初始化但为启动的线程。当JVM开始执行关闭序列时，它才开始已某种随机程序注册和并行执行shutdown hooks。 注意 这个对 kill -9 {pid} 无效，对 kill -15 及 Control +C 有效 12345678910111213//注册钩子函数Runtime.getRuntime().addShutdownHook(new Thread(() -&gt; &#123; log.info("开始停止任务"); //停止标识位 为 true 停止从kafka 拿数据 isStop = true; try &#123; //阻塞 直到将已经拿到的数据处理完毕 executorService.awaitTermination(1, TimeUnit.HOURS); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; log.info("任务已经停止"); &#125;)); SignalHandler实现sun.misc.SignalHandler 接口 12345678910111213141516public class SignalHandlerImp implements SignalHandler &#123; public void handle(Signal signal) &#123; //停止标识位 为 true 停止从kafka 拿数据 isStop = true; try &#123; //阻塞 直到将已经拿到的数据处理完毕 executorService.awaitTermination(1, TimeUnit.HOURS); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; log.info("任务已经停止"); System.out.println(signal.getName()+":"+signal.getNumber()); &#125;&#125; 123456// 注册要监听的信号 SignalHandlerImp signalHandlerImp = new SignalHandlerImp(); Signal.handle(new Signal("INT"), signalHandlerImp);// 2 : 中断（同 ctrl + c ） Signal.handle(new Signal("TERM"), signalHandlerImp);// 15 : 正常终止 Signal.handle(new Signal("USR2"), signalHandlerImp);// 12 : 用户自定义信号 总结jvm 关闭的几种方式 我们可以通过 钩子函数来 处理 正常关闭以及异常关闭的收尾工作。SignalHandler 只能处理正常关闭的收尾工作。所以钩子函数的应用要广泛一点的。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用shrio来管理权限]]></title>
    <url>%2F2019%2F09%2F30%2F%E4%BD%BF%E7%94%A8shrio%E6%9D%A5%E7%AE%A1%E7%90%86%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[前言最近公司我负责的一个服务（spring-boot spring-could）需要在接口级别做权限控制，本来想着是在controller层加上注解，再通过切面（aop）来实现。后来发现网上有现成的框架spring shrio 以及spring security。某位大佬曾经说过：不要重复造轮子。本着这个原则去了解了这两个框架。 选型简单看了一下两个框架最后选择了spring shrio。这里说一下原因spring security接口设计有点问题，对用户的入侵有点太强了，扩展性不够。简单举个列子 使用security需要实现下面的接口。 这个接口只有一个方法，用户用户名获得用户相关的信息，及其权限信息。 我的那个微服务，需要通过用户及用户当前选择的数据源来获得权限信息（每个用户的每个数据源都具有不同的权限）。 这里就明显不符合要求。所以最后选择了spring shrio 整合过程依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.shiro&lt;/groupId&gt; &lt;artifactId&gt;shiro-spring-boot-web-starter&lt;/artifactId&gt; &lt;version&gt;1.5.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt; 配置12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Configurationpublic class ShiroConfig &#123; private static String[] withOutAuthUrl = new String[]&#123; "/auth/**", "/error", "/actuator/*", "/", "/**/*swagger*/**" &#125;; @Bean public SessionsSecurityManager securityManager() &#123; DefaultWebSecurityManager securityManager = new DefaultWebSecurityManager(); //定义AuthorizingRealm securityManager.setRealm(new WebRealm()); //设置缓存管理器这里使用内存 securityManager.setCacheManager(new MemoryConstrainedCacheManager()); //关闭shrio自带的session DefaultSubjectDAO subjectDAO = new DefaultSubjectDAO(); DefaultSessionStorageEvaluator defaultSessionStorageEvaluator = new DefaultSessionStorageEvaluator(); defaultSessionStorageEvaluator.setSessionStorageEnabled(false); subjectDAO.setSessionStorageEvaluator(defaultSessionStorAuthorizingRealmageEvaluator); securityManager.setSubjectDAO(subjectDAO); return securityManager; &#125; @Bean(name = "shiroFilterFactoryBean") public ShiroFilterFactoryBean shirFilter(SecurityManager securityManager) &#123; ShiroFilterFactoryBean shiroFilterFactoryBean = new ShiroFilterFactoryBean(); shiroFilterFactoryBean.setSecurityManager(securityManager); Map&lt;String, Filter&gt; filterMap = Maps.newHashMap(); shiroFilterFactoryBean.setFilters(filterMap); //添加自定义过滤器 filterMap.put("authFilter", new ShiroAuthFilter()); Map&lt;String, String&gt; filterRuleMap = Maps.newHashMap(); //不需要通过过滤器的url for (String url : withOutAuthUrl) &#123; filterRuleMap.put(url, "anon"); &#125; //定义过滤规则 filterRuleMap.put("/**", "authFilter"); shiroFilterFactoryBean.setFilterChainDefinitionMap(filterRuleMap); return shiroFilterFactoryBean; &#125; /** * 下面的代码是添加注解支持 */ @Bean @DependsOn("lifecycleBeanPostProcessor") public DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator() &#123; DefaultAdvisorAutoProxyCreator defaultAdvisorAutoProxyCreator = new DefaultAdvisorAutoProxyCreator(); // 强制使用cglib，防止重复代理和可能引起代理出错的问题 // https://zhuanlan.zhihu.com/p/29161098 defaultAdvisorAutoProxyCreator.setProxyTargetClass(true); return defaultAdvisorAutoProxyCreator; &#125;&#125; 自定义token 这个token是包含自己需要用来做权限的所有信息的实体，在我这主要包含，当前用户及其选择的数据源的信息 1234567891011121314151617181920/** * @author jianganwei * @date 2019/9/29 */public class AuthToken implements AuthenticationToken &#123; private AuthModel authModel; public AuthToken(AuthModel authModel) &#123; this.authModel = authModel; &#125; @Override public Object getPrincipal() &#123; return authModel; &#125; @Override public Object getCredentials() &#123; return authModel; &#125;&#125; 定义AuthorizingRealm 1234567891011121314151617181920212223242526272829303132333435@Component@Slf4jpublic class WebRealm extends AuthorizingRealm &#123; //获得权限信息接口，这个接口的结果会缓存，不会每次都调用 @Override protected AuthorizationInfo doGetAuthorizationInfo(PrincipalCollection principalCollection) &#123; AuthModel authModel = (AuthModel)principalCollection.getPrimaryPrincipal(); SimpleAuthorizationInfo authorizationInfo = new SimpleAuthorizationInfo(); //这里从数据获得权限信息 一下为测试代码 if(authModel.getDataSourceEntity().getGraphBean().equals("ick_graph"))&#123; authorizationInfo.addStringPermission("schema:read"); &#125;else &#123; authorizationInfo.addStringPermission("dataSource:get"); &#125; log.debug("授权:&#123;&#125;", authModel); return authorizationInfo; &#125; /** *添加对自定义的token的支持 **/ @Override public boolean supports(AuthenticationToken token) &#123; return token instanceof AuthToken; &#125; //认证接口 @Override protected AuthenticationInfo doGetAuthenticationInfo(AuthenticationToken authenticationToken) throws AuthenticationException &#123; log.debug("认证"); return new SimpleAuthenticationInfo(authenticationToken.getPrincipal(), authenticationToken.getCredentials(), WebRealm.class.getTypeName()); &#125;&#125; 自定义过滤器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889@Component@Slf4jpublic class ShiroAuthFilter extends AccessControlFilter &#123; private static String[] withOutDataSourceUrl = new String[]&#123; "/user/dataSource", "/dataSource/all" &#125;; private AntPathMatcher antPathMatcher = new AntPathMatcher(); /** * 表示当访问拒绝时是否已经处理了；如果返回true表示需要继续处理；如果返回false表示该拦截器实例已经处理了，将直接返回即可。 * * @param request * @param response * @return * @throws Exception */ @Override protected boolean onAccessDenied(ServletRequest request, ServletResponse response) throws Exception &#123; log.info("onAccessDenied"); return false; &#125; /** * 表示是否允许访问；mappedValue就是[urls]配置中拦截器参数部分，如果允许访问返回true，否则false； * (感觉这里应该是对白名单（不需要登录的接口）放行的) * 如果isAccessAllowed返回true则onAccessDenied方法不会继续执行 * 这里可以用来判断一些不被通过的链接（个人备注） * * 表示是否允许访问 ，如果允许访问返回true，否则false； * * @param request * @param response * @param mappedValue 表示写在拦截器中括号里面的字符串 mappedValue 就是 [urls] 配置中拦截器参数部分 * @return * @throws Exception */ @Override protected boolean isAccessAllowed(ServletRequest request, ServletResponse response, Object mappedValue) &#123; Subject subject = getSubject(request, response); String url = getPathWithinApplication(request); log.debug("当前用户正在访问的 url =&gt; &#123;&#125; ", url); log.debug("subject.isPermitted(url);&#123;&#125;", subject.isPermitted(url)); AuthService authService = SpringUtils.getBean(AuthService.class); //FeignClient 远程调用 用户中心微服务获得用户信息 AuthModel authModel = authService.getUserInfoFromAuth3Client((HttpServletRequest) request); if (null == authModel) &#123; //未登录 response401(response); return false; &#125; //从cookie中获得数据源信息 DataSourceEntity dataSourceEntity = authService.getDataSourceFromCookie((HttpServletRequest) request); authModel.setDataSourceEntity(dataSourceEntity); if (Stream.of(withOutDataSourceUrl).anyMatch(x -&gt; antPathMatcher.match(x, url))) &#123; log.debug("接口：&#123;&#125; 不需要选择数据源", url); getSubject(request, response).login(new AuthToken(authModel)); return true; &#125; if (null == dataSourceEntity) &#123; response402(response); return false; &#125; //这个方法最终会调用WebRealm#doGetAuthenticationInfo //表示通过认证 getSubject(request, response).login(new AuthToken(authModel)); return true; &#125; private void response401(ServletResponse response) &#123; try &#123; response.getWriter().write(JSON.toJSONString(new ResultData("401", "not choose dataSource", ""))); response.getWriter().flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; private void response402(ServletResponse response) &#123; try &#123; response.getWriter().write(JSON.toJSONString(new ResultData("402", "not choose dataSource", ""))); response.getWriter().flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 问题在修改了权限后需要清空缓存，当我是用下面的方法清除缓存的时候发现清除不掉 1sessionsSecurityManager.getCacheManager().getCache(WebRealm.class.getName() + ".authorizationCache").remove(authModel); 跟它的源码发现内存的缓存使用Map来做的，我传入的AuthModel 是不同的对象，需要用SimplePrincipalCollection来包装一下。 1sessionsSecurityManager.getCacheManager().getCache(WebRealm.class.getName() + ".authorizationCache").remove(new SimplePrincipalCollection(authModel, WebRealm.class.getTypeName())); 注意复写AuthModel的hashcode及equels方法 懒的话可以将对象转为jsonString 12345678910111213141516public class AuthToken implements AuthenticationToken &#123; private AuthModel authModel; public AuthToken(AuthModel authModel) &#123; this.authModel = authModel; &#125; @Override public Object getPrincipal() &#123; return JSON.toJSONString(authModel); &#125; @Override public Object getCredentials() &#123; return JSON.toJSONString(authModel); &#125;&#125; 需要用到的时候转回来就好了]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>shrio</tag>
        <tag>权限管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring Bean创建流程及扩展点]]></title>
    <url>%2F2019%2F09%2F26%2Fspring%20Bean%E5%88%9B%E5%BB%BA%E6%B5%81%E7%A8%8B%E5%8F%8A%E6%89%A9%E5%B1%95%E7%82%B9%2F</url>
    <content type="text"><![CDATA[springBean创建流程 扩展点ImportBeanDefinitionRegistrar 与ImportSelector实现接口可以添加自定义的beanDefinition，例： 12345678910@Componentpublic class RpcClientSelector implements ImportBeanDefinitionRegistrar &#123; @Override public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry) &#123; Map&lt;String, Object&gt; map = importingClassMetadata.getAnnotationAttributes(EnableRpcClient.class.getName()); BeanDefinitionBuilder beanDefinitionBuilder = BeanDefinitionBuilder.rootBeanDefinition(RpcScanner.class); beanDefinitionBuilder.addPropertyValue("basePackage", map.get("basePackage")); registry.registerBeanDefinition(RpcScanner.class.getName(), beanDefinitionBuilder.getBeanDefinition()); &#125;&#125; BeanDefinitionBuilder.rootBeanDefinition(clazz); 如果clazz 实现了FactoryBean那么创建的bean 的类型不是clazz本身，而是getObject() 方法返回的对象类型 123456789@Componentpublic class RpcClientSelector implements ImportSelector &#123; @Override public String[] selectImports(AnnotationMetadata importingClassMetadata) &#123; Set&lt;String&gt; strings = importingClassMetadata.getMetaAnnotationTypes(RpcClient.class.getName()); Set&lt;String&gt; strings1 = importingClassMetadata.getAnnotationTypes(); return new String[]&#123;"com.jianganwei.rpcclient.selector.RpcScanner"&#125;; &#125;&#125; BeanFactoryPostProcessor添加修改bean 12345678910111213141516@Componentpublic class MyConfigBean implements BeanFactoryPostProcessor &#123; @Override public void postProcessBeanFactory ( ConfigurableListableBeanFactory beanFactory) throws BeansException &#123; GenericBeanDefinition bd = new GenericBeanDefinition(); bd.setBeanClass(MyBean.class); bd.getPropertyValues().add("strProp", "my string property"); ((DefaultListableBeanFactory) beanFactory) .registerBeanDefinition("myBeanName", bd); &#125;&#125; BeanPostProcessorbean的初始化过程（初始化，之前初始化之后） 总结通过上面的扩展点可以动态修改bean然后注入到代码中，注入动态代理后的bean都是基于这些扩展点完成的。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次mysql分页问题]]></title>
    <url>%2F2019%2F09%2F15%2F%E8%AE%B0%E4%B8%80%E6%AC%A1mysql%E5%88%86%E9%A1%B5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前言都知道mysql分页使用limit这个关键字来进行的，但今天使用这个关键之进行分页点时候出现了点问题，有些记录没有查到，有些记录在上一页出现之后，翻下一页又出现了。 问题分析单独使用limit这个关键字是没有问题的，加上order by 这个关键字之后排序就会出现上述问题，猜想order by 这个关键字与limit会相互影响。 问题重现先准备需要查询的数据 分别执行sql select from limit_test order by score limit 5，select from limit_test order by score limit 5，10 得到结果 结果发现id为8的这条记录出现了2次而id为6的记录没有出现，重现了该问题。 解决问题小弟束手无策，这个时候只有请求google大神了，最后在mysql官网找到了这个问题的原因 https://dev.mysql.com/doc/refman/5.7/en/limit-optimization.html 原因大概是order by 和limit 组合使用的时候,mysql 会将不会整体排序，而是到了需要查的数据量(limit 的值)的时候，就不会进行排序了，而order by 字段相同值记录的顺序是不确定的，所以导致了上面的问题 解决办法在order by子句中包含附加列，使顺序具有确定性。比如加上唯一的主键id。 例如： select * from limit_test order by score,id limit 5 总结用了mysql 这么久，以为对它已经很熟悉了，结果还是太年轻，学习之路，任重道远啊！！]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es学习笔记-基础篇]]></title>
    <url>%2F2019%2F07%2F31%2Fes%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[索引–保存相关数据的地方，实际上是指向一个或者多个物理分片的逻辑明名空间。 集群内的原理es支持垂直扩容，水平扩容，但是垂直扩容是有极限的，真正的扩容能力来自于水平扩容（为集群添加更多的节点，并将负载及稳定性型分散到这些节点中） 一个运行中的es实例称为一个节点，集群就是由多个拥有相同cluster.name节点组成，集群中有一个节点会被选中为主节点。主节点负责集群范围内所有索引（存储文档的数据库）及节点的新增，及删除等，主节点不会参与到文档添加及更新，所以只有一个主节点不会成为性能的瓶颈。用户可以把请求发送到任意一个节点，每个节点知道任意文档所在的位置，它能找到文档所在的各个节点并搜集返回到客户端。 集群健康1GET /_cluster/health 1234567891011121314151617&#123;"cluster_name": "elasticsearch","status": "green","timed_out": false,"number_of_nodes": 4,"number_of_data_nodes": 4,"active_primary_shards": 15,"active_shards": 30,"relocating_shards": 0,"initializing_shards": 0,"unassigned_shards": 0,"delayed_unassigned_shards": 0,"number_of_pending_tasks": 0,"number_of_in_flight_fetch": 0,"task_max_waiting_in_queue_millis": 0,"active_shards_percent_as_number": 100&#125; status字段表示集群总体工作状态 green 所有主分片和副分片都正常运行。yellow主分片正常运行，但是不是所有的副分片都正常运行。red有主分片没有正常运行。 索引分片1PUT /&#123;index_name&#125; 123456&#123;"settings":&#123; "number_of_shards":5,//索引分片数目 "number_of_replicas":1//备份数量&#125;&#125; 索引–保存相关数据的地方，实际上是指向一个或者多个物理分片的逻辑明名空间。分片是数据的容器，文档被保存在分片里，分片被保存在各个节点里面。当集群规模扩大或者缩小，es会自动迁移分片，使得数据均匀分布在各个节点上面。 一个分片理论上能存储 Integer.MAX_VALUE-128个文档，具体和文档大小，及硬件有关。所以一个索引能存储的最大文档数量由分片数目决定。 数据输入和输出文档元数据_index 文档存放在哪儿 索引名字 参照关系数据库的数据库名字 _type 同一个索引下的不同数据类型 参照关系数据库的表名 _version （版本）号，当文档被修改时版本号递增 _id _id及 _type 、_index 可以唯一确定一个es文档,可以自己提供，也可以由es生成 _all 将所有字段拼接在一起，用于全文搜索 文档操作添加文档123456PUT /&#123;index&#125;/&#123;type&#125;/&#123;id&#125;&#123;&quot;fileds&quot;:&quot;values&quot;....&#125;PUT /&#123;index&#125;/&#123;type&#125;/?op_type=createPUT /&#123;index&#125;/&#123;type&#125;/_reate 搜索文档1234567891011121314GET /&#123;index&#125;/&#123;type&#125;/&#123;id&#125;HEAD /&#123;index&#125;/&#123;type&#125;/&#123;id&#125; //检查文档是否存在GET /&#123;index&#125;/&#123;type&#125;/_search //该索引该类型返回所有文档GET /&#123;index&#125;/&#123;type&#125;/&#123;id&#125;?_source=title,text //返回文档的一部分GET _mget //取回多个文档 也可以在url中指定默认的index 及type&#123; &quot;docs&quot; : [ &#123; &quot;_index&quot; : &quot;janusgraph_test_node_index&quot;, &quot;_type&quot; : &quot;test_node_index&quot;, &quot;_id&quot; : &quot;147ig&quot; &#125; ]&#125; 更新文档1PUT /&#123;index&#125;/&#123;type&#125;/&#123;id&#125; 创建文档12POST /&#123;index&#125;/&#123;type&#125;/PUT /&#123;index&#125;/&#123;type&#125;/ 删除文档1DELETE /&#123;index&#125;/&#123;type&#125;/&#123;id&#125; 乐观并发控制es为每个文档维护了一个版本号_version 修改数据的时候可以指定版本号 PUT /{index}/{type}/{id}?version=1 ，通过指定想要修改文档的 version 号来达到这个目的。 如果该版本不是当前版本号，我们的请求将会失败。 也可以使用外部系统的版本号PUT /{index}/{type}/{id}?version=1&amp;version_type=external 外部版本号的处理方式和我们之前讨论的内部版本号的处理方式有些不同， Elasticsearch 不是检查当前_version和请求中指定的版本号是否相同， 而是检查当前_version是否 *小于* 指定的版本号。 如果请求成功，外部的版本号作为文档的新_version` 进行存储。 搜索返回字段hits:返回结果中最重要的部分是 hits ，它 包含 total 字段来表示匹配到的文档总数，并且一个 hits 数组包 含所查询结果的前十个文档。在 hits 数组中每个结果包含文档的 _index 、 _type 、 _id ，加上 _source 字段。每个结果还有一个 _score ，它衡量了文档与查询的匹配程度。 took 执行整个搜索请求耗费了多少毫秒。 _shards参与分片的总数，以及这些分片成功了多少个失败了多少个。 timed_out 询是否超时。 多索引多类型搜索/_search 在所有的索引中搜索所有的类型 /gb/_search 在 gb 索引中搜索所有的类型 /gb,us/_search 在 gb 和 us 索引中搜索所有的文档 /g\*,u\*/_search 在任何以 g 或者 u 开头的索引中搜索所有的类型 /gb/user/_search 在 gb 索引中搜索 user 类型 /gb,us/user,tweet/_search 在 gb 和 us 索引中搜索 user 和 tweet 类型 /_all/user,tweet/_search 在所有的索引中搜索 user 和 tweet 类型 分页1GET /_search?size=5&amp;from=5 映射与分析es 支持精确搜索和全文搜索，精确搜索就是严格的相等；全文搜索，就是会对词进行分析，比如搜索中国，能得到中华人民共和国 这样的结果 倒排索引Elasticsearch 使用一种称为 倒排索引 的结构，它适用于快速的全文搜索。一个倒排索引由文档中所有不重复词的列表构成，对于其中每个词，有一个包含它的文档列表。 例如，假设我们有两个文档，每个文档的 content 域包含如下内容： The quick brown fox jumped over the lazy dog Quick brown foxes leap over lazy dogs in summer 为了创建倒排索引，我们首先将每个文档的 content 域拆分成单独的 词（我们称它为 词条 或 tokens ），创建一个包含所有不重复词条的排序列表，然后列出每个词条出现在哪个文档。结果如下所示： 123456789101112131415161718Term Doc_1 Doc_2-------------------------Quick | | XThe | X |brown | X | Xdog | X |dogs | | Xfox | X |foxes | | Xin | | Xjumped | X |lazy | X | Xleap | | Xover | X | Xquick | X |summer | | Xthe | X |------------------------ 现在，如果我们想搜索 quick brown ，我们只需要查找包含每个词条的文档： 123456Term Doc_1 Doc_2-------------------------brown | X | Xquick | X |------------------------Total | 2 | 1 两个文档都匹配，但是第一个文档比第二个匹配度更高。如果我们使用仅计算匹配词条数量的简单 相似性算法 ，那么，我们可以说，对于我们查询的相关性来讲，第一个文档比第二个文档更佳。 倒排索引还会有一些问题，比如，大小写，还有相同意思的单词。这就需要分析器来处理了。 分析与分析器分析器包含三个部分的功能 字符过滤器 首先，字符串按顺序通过每个 字符过滤器 。他们的任务是在分词前整理字符串。一个字符过滤器可以用来去掉HTML，或者将 &amp; 转化成 and。 分词器 其次，字符串被 分词器 分为单个的词条。一个简单的分词器遇到空格和标点的时候，可能会将文本拆分成词条。 Token 过滤器 最后，词条按顺序通过每个 token 过滤器 。这个过程可能会改变词条（例如，小写化 Quick ），删除词条（例如， 像 a， and， the 等无用词），或者增加词条（例如，像 jump 和 leap 这种同义词）。 内置分析器标准分析器 标准分析器是Elasticsearch默认使用的分析器。它是分析各种语言文本最常用的选择。它根据 Unicode 联盟 定义的 单词边界 划分文本。删除绝大部分标点。 简单分析器 简单分析器在任何不是字母的地方分隔文本，将词条小写。 空格分析器 空格分析器在空格的地方划分文本。它会产生 语言分析器 特定语言分析器可用于 很多语言。它们可以考虑指定语言的特点。例如， 英语 分析器附带了一组英语无用词（常用单词，例如 and 或者 the ，它们对相关性没有多少影响），它们会被删除。 由于理解英语语法的规则，这个分词器可以提取英语单词的 词干 。 12345GET /_analyze&#123; &quot;analyzer&quot;: &quot;standard&quot;, &quot;text&quot;: &quot;Text to analyze&quot;&#125; 映射内部对象的数组是如何被索引的。 假设我们有个 followers 数组： 1234567&#123; "followers": [ &#123; "age": 35, "name": "Mary White"&#125;, &#123; "age": 26, "name": "Alex Jones"&#125;, &#123; "age": 19, "name": "Lisa Smith"&#125; ]&#125; 这个文档会像我们之前描述的那样被扁平化处理，结果如下所示： 1234&#123; "followers.age": [19, 26, 35], "followers.name": [alex, jones, lisa, smith, mary, white]&#125; 内部对象如何映射 123456789&#123; "tweet": [elasticsearch, flexible, very], "user.id": [@johnsmith], "user.gender": [male], "user.age": [26], "user.name.full": [john, smith], "user.name.first": [john], "user.name.last": [smith]&#125; 内部域 可以通过名称引用（例如， first ）。为了区分同名的两个域，我们可以使用全 路径 （例如， user.name.first ） 或 type 名加路径（ tweet.user.name.first ）。 查询查询表达式一个查询语句 的典型结构： 123456&#123; QUERY_NAME: &#123; ARGUMENT: VALUE, ARGUMENT: VALUE,... &#125;&#125; 如果是针对某个字段，那么它的结构如下： 12345678&#123; QUERY_NAME: &#123; FIELD_NAME: &#123; ARGUMENT: VALUE, ARGUMENT: VALUE,... &#125; &#125;&#125; 主要的ARGUMENTmatch_all:查询简单的 匹配所有文档。 match:无论你在任何字段上进行的是全文搜索还是精确查询，match 查询是你可用的标准查询。 multi_match:查询可以在多个字段上执行相同的 match 查询 range:查询找出那些落在指定区间内的数字或者时间 term:查询被用于精确值 匹配，这些精确值可能是数字、时间、布尔或者那些 not_analyzed 的字符串 terms:terms 查询和 term 查询一样，但它允许你指定多值进行匹配。它查询那些精确匹配的值（包括在大小写、重音、空格等方面的差异）。 exits:文档中某个属性有值 missing:同exits相反 多组合查询1234567891011121314151617181920&#123; "bool": &#123; "must": &#123; "match": &#123; "title": "how to make millions" &#125;&#125;, "must_not": &#123; "match": &#123; "tag": "spam" &#125;&#125;, "should": [ &#123; "match": &#123; "tag": "starred" &#125;&#125; ], "filter": &#123; "bool": &#123; "must": [ &#123; "range": &#123; "date": &#123; "gte": "2014-01-01" &#125;&#125;&#125;, &#123; "range": &#123; "price": &#123; "lte": 29.99 &#125;&#125;&#125; ], "must_not": [ &#123; "term": &#123; "category": "ebooks" &#125;&#125; ] &#125; &#125; &#125;&#125; 排序123456789101112GET /_search&#123; &quot;query&quot; : &#123; &quot;bool&quot; : &#123; &quot;filter&quot; : &#123; &quot;term&quot; : &#123; &quot;user_id&quot; : 1 &#125;&#125; &#125; &#125;, &quot;sort&quot;:[ &#123; &quot;date&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125;, &#123; &quot;_score&quot;: &#123; &quot;order&quot;: &quot;desc&quot; &#125;&#125; ]&#125; 索引管理创建索引123456789PUT /my_index&#123; "settings": &#123; ... any settings ... &#125;, "mappings": &#123; "type_one": &#123; ... any mappings ... &#125;, "type_two": &#123; ... any mappings ... &#125;, ... &#125;&#125; 删除索引1DELETE /my_index 配置分析器12345678910111213PUT /spanish_docs&#123; "settings": &#123; "analysis": &#123; "analyzer": &#123; "es_std": &#123; "type": "standard", "stopwords": "_spanish_" &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>es</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JanusGraph学习笔记]]></title>
    <url>%2F2019%2F07%2F15%2FJanusGraph%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[jansusgraph是一款分布式开源图数据库。 JanusGraph Server使用默认的数据库及搜索引擎配置：bin/janusgraph.sh start 自定义存储及搜索引擎：bin/gremlin-server.sh ./conf/gremlin-server/gremlin-server.yaml gremlin-server.yaml内容： 1234567891011121314host: localhostport: 8182scriptEvaluationTimeout: 120000# ws+httpchannelizer: org.apache.tinkerpop.gremlin.server.channel.WsAndHttpChannelizer#http#channelizer: org.apache.tinkerpop.gremlin.server.channel.HttpChannelizer#ws#channelizer: org.apache.tinkerpop.gremlin.server.channel.WebSocketChannelizergraphs: &#123;#数据库及搜索引擎配置 graph: conf/gremlin-server/socket-janusgraph-hbase-server.properties&#125;.............. 发送http请求1234567891011121314POST HTTP/1.1Host: localhost:8182Content-Type: application/jsonUser-Agent: PostmanRuntime/7.19.0Accept: */*Cache-Control: no-cachePostman-Token: c8c2454d-8daa-4ac4-ad4c-1d9ad784a6bb,c6e81a95-2862-4cfb-a8ef-3cbcfa8c482cHost: 172.16.21.46:8182Accept-Encoding: gzip, deflateContent-Length: 36Connection: keep-alivecache-control: no-cache&#123;&quot;gremlin&quot;: &quot;g.V().limit(1).next()&quot;&#125; socket-janusgraph-hbase-server.properties内容： 12345678910111213gremlin.graph=org.janusgraph.core.JanusGraphFactorystorage.backend=hbasestorage.hostname=3-142-bigdata-2.jianganwei.com,3-141-bigdata-1.jianganwei.com,3-143-bigdata-3.jianganwei.comstorage.batch-loading=truestorage.hbase.table=janusgraph_demo_x //hbase表名字ids.block-size=100000000storage.hbase.ext.zookeeper.znode.parent=/hbase-unsecurecache.db-cache = truecache.db-cache-clean-wait = 20cache.db-cache-time = 180000cache.db-cache-size = 0.5index.search.backend=elasticsearchindex.search.hostname=127.0.0.1 还有权限认证功能 见 官方文档 Gremlin终端连接远程数据库1:remote connect tinkerpop.server conf/remote.yaml remote.yaml : 123hosts: [localhost]port: 8182serializer: &#123; className: org.apache.tinkerpop.gremlin.driver.ser.GryoMessageSerializerV1d0, config: &#123; serializeResultToString: true &#125;&#125; 基础语句 graph = JanusGraphFactory.open(&#39;conf/gremlin-server/socket-janusgraph-hbase-server.properties&#39;) 打开数据库连接 g=graph.traversal() 的到实列 V()：查询顶点，一般作为图查询的第1步，后面可以续接的语句种类繁多。例，g.V()，g.V(&#39;v_id&#39;)，查询所有点和特定点； E()：查询边，一般作为图查询的第1步，后面可以续接的语句种类繁多； id()：获取顶点、边的id。例：g.V().id()，查询所有顶点的id； label()：获取顶点、边的 label。例：g.V().label()，可查询所有顶点的label。 key() / values()：获取属性的key/value的值。 properties()：获取顶点、边的属性；可以和 key()、value()搭配使用，以获取属性的名称或值。例：g.V().properties(&#39;name&#39;)，查询所有顶点的 name 属性； valueMap()：获取顶点、边的属性，以Map的形式体现，和properties()比较像； values()：获取顶点、边的属性值。例，g.V().values() 等于 g.V().properties().value() 遍历（以定点为基础） out(label)：根据指定的 Edge Label 来访问顶点的 OUT 方向邻接点（可以是零个 Edge Label，代表所有类型边；也可以一个或多个 Edge Label，代表任意给定 Edge Label 的边，下同）； in(label)：根据指定的 Edge Label 来访问顶点的 IN 方向邻接点； both(label)：根据指定的 Edge Label 来访问顶点的双向邻接点； outE(label)： 根据指定的 Edge Label 来访问顶点的 OUT 方向邻接边； inE(label)：根据指定的 Edge Label 来访问顶点的 IN 方向邻接边； bothE(label)：根据指定的 Edge Label 来访问顶点的双向邻接边； 遍历（以边为基础） outV()：访问边的出顶点，出顶点是指边的起始顶点； inV()：访问边的入顶点，入顶点是指边的目标顶点，也就是箭头指向的顶点； bothV()：访问边的双向顶点； otherV()：访问边的伙伴顶点，即相对于基准顶点而言的另一端的顶点； 过滤 has(key,value): 通过属性的名字和值来过滤顶点或边； has(label, key, value): 通过label和属性的名字和值过滤顶点和边； has(key,predicate): 通过对指定属性用条件过滤顶点和边，例：g.V().has(&#39;age&#39;, gt(20))，可得到年龄大于20的顶点； hasLabel(labels…): 通过 label 来过滤顶点或边，满足label列表中一个即可通过； hasId(ids…): 通过 id 来过滤顶点或者边，满足id列表中的一个即可通过； hasKey(keys…): 通过 properties 中的若干 key 过滤顶点或边； hasValue(values…): 通过 properties 中的若干 value 过滤顶点或边； has(key): properties 中存在 key 这个属性则通过，等价于hasKey(key)； hasNot(key): 和 has(key) 相反； 分支（if-else） choose(predicate,true,false) :判断第一个参数的条件，满足走true分支，不满足走false分支可以与optional()搭配使用。列子： 12345678g.V().hasLabel('person'). choose(values('age').is(lte(30)), __.in(), __.out()).values('name') g.V().hasLabel('person'). choose(values('age')). option(27, __.in()). option(32, __.out()).values('name') 循环 repeat()：指定要重复执行的语句； times()： 指定要重复执行的次数，如执行3次； until()：指定循环终止的条件，如一直找到某个名字的朋友为止； loops()：当前循环的次数，可用于控制最大循环次数等，如最多执行3次。 repeat() 和 until() 的位置不同，决定了不同的循环效果： repeat() + until()：等同 do-while； until() + repeat()：等同 while-do 12345678g.V(1) .repeat(out()) .until(outE().count().is(0)) .path().by('name') g.V('1') .repeat(out()) .until(loops().is(3)) .path() Match匹配数据类似neo4j的match 和as()配合使用 123456g.V().match( __.as('a').out('created').as('b'), __.as('b').has('name', 'lop'), __.as('b').in('created').as('c'), __.as('c').has('age', 29)). select('a','c').by('name') project通过by来进行分支运算 123g.V().groupCount().by(label()).unfold().project('k','v').by(map&#123;it-&gt;it.get().getKey()&#125;).by(map&#123;it-&gt;it.get().getValue()&#125;).order().by(select('v'))g.V().groupCount().by(label()).unfold().project('k','v','v1').by(map&#123;it-&gt;it.get().getValue()&#125;).by(map&#123;it-&gt;it.get().getKey()&#125;).by(map&#123;it-&gt;it.get().getValue()&#125;) 路径 path()当前遍历过的路径 simplePath()过滤掉路径中含有环路的对象 cyclicPath()过滤掉路径中不含有环路的对象 shortestPath()最短路径 1g.V().shortestPath().with(ShortestPath.edges, Direction.IN).with(ShortestPath.target, __.has('name','josh')) 统计 sum()：将 traversal 中的所有的数字求和； max()：对 traversal 中的所有的数字求最大值； min()：对 traversal 中的所有的数字求最小值； mean()：将 traversal 中的所有的数字求均值； count()：统计 traversal 中 item 总数。 or这个也是一个过滤语句 1g.V().or(out().has('test','test'),in().has('test','test')) 注意这里返回的是 满足or 里面任一条件的 节点，而不是返回in或者out之后的节点 和下面的语句等价 1g.V().where(out().has('test','test').or().in().has('test','test')) and,not 和这个类似 union联合多个结果 比如需要查 某个节点的 in() 和out()节点 1g.V().union(__.in(),out()) 当然这里可以用both代替，如果遇到比较复杂的联合就需要 union 更多语法见官方文档 批量导入janusGraph 本身不带有导入功能 我们使用github 开源工具 https://github.com/IBM/janusgraph-utils 下载工具ropo 打包123git clone https://github.com/IBM/janusgraph-utils.gitcd janusgraph-utils/mvn package 根据配置生成模版文件： 1./run.sh gencsv csv-conf/twitter-like-w-date.json /tmp 里面包括schama.json 描述各个字段类型，及索引等等，datamapper.json 描述各个节点及边所在的文件名，及各个字段对应关系。 导入数据设置环境变量 12export JANUSGRAPH_HOME=/opt/app/janusgraph-0.3.1-hadoop2export PATH=$PATH:$JANUSGRAPH_HOME/bin 1./run.sh import ~/janusgraph/conf/janusgraph-cql-es.properties /tmp /tmp/schema.json /tmp/datamapper.json 批量导入官方版本官方导入方式 注意配置 hadoop 环境变量 最新版本的 环境变量 123export HADOOP_CONF_DIR=/etc/hadoop/confexport CLASSPATH=$HADOOP_CONF_DIRbin/gremlin.sh 配置文件 1234567891011gremlin.graph=org.apache.tinkerpop.gremlin.hadoop.structure.HadoopGraph##读取数据的格式gremlin.hadoop.graphReader=org.janusgraph.hadoop.formats.cassandra.Cassandra3InputFormatgremlin.hadoop.graphWriter=org.apache.tinkerpop.gremlin.hadoop.structure.io.gryo.GryoOutputFormatgremlin.hadoop.jarsInDistributedCache=true##输入文件地址gremlin.hadoop.inputLocation=nonegremlin.hadoop.outputLocation=outputgremlin.spark.persistContext=true........ 12345678:load data/grateful-dead-janusgraph-schema.groovygraph = JanusGraphFactory.open('conf/gremlin-server/jianganwei-janusgraph-hbase-server.properties')defineGratefulDeadSchema(graph)graph.close()hdfs.copyFromLocal('data/grateful-dead.kryo','data/grateful-dead.kryo')graph = GraphFactory.open('conf/hadoop-graph/hadoop-graphson.properties')blvp = BulkLoaderVertexProgram.build().writeGraph('conf/gremlin-server/jianganwei-janusgraph-hbase-server.properties').create(graph)graph.compute(SparkGraphComputer).program(blvp).submit().get() 清除数据1234:i org.janusgraph.core.util.JanusGraphCleanup graph = JanusGraphFactory.open('conf/gremlin-server/jianganwei-janusgraph-hbase-server.properties')graph.close()JanusGraphCleanup.clear(graph) 查看schema123graph = JanusGraphFactory.open('conf/gremlin-server/jianganwei-janusgraph-hbase-server.properties')mgmt = graph.openManagement()mgmt.printSchema() 添加节点12345678tx = graph.newTransaction()vertex = tx.addVertex("Customer")vertex.property("id_no",510800200000000000)vertex.property("cust_no","123")vertex.property("cust_name","李四")vertex.property("gender","男")vertex.property("create_time",new java.util.Date())tx.commit() 添加边1234left=g.V(7372800004272).next()right=g.V(8216).next()edge=left.addEdge("CALL", right)edge.property("content","我好想你") 建立混合索引12345indexBuilder = mgmt.buildIndex("call_content_index", Edge.class)indexBuilder.indexOnly(mgmt.getEdgeLabel("CALL"))indexBuilder.unique();indexBuilder.addKey(mgmt.getPropertyKey("content"), Mapping.STRING.asParameter())indexBuilder.buildMixedIndex("search") 建立精准索引12345indexBuilder = mgmt.buildIndex("test_set_index", Vertex.class)indexBuilder.indexOnly(mgmt.getVertexLabel("Customer"))indexBuilder.unique();indexBuilder.addKey(mgmt.getPropertyKey("test_set"));indexBuilder.buildCompositeIndex(); 添加属性1mgmt.makePropertyKey("content").dataType(java.lang.String.class).cardinality(Cardinality.SINGLE).make() 按混合索引查询数据1graph.indexQuery("call_content_index","你").edgeTotals()]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>JanusGraph</tag>
        <tag>图数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spring事务]]></title>
    <url>%2F2019%2F04%2F12%2Fspring%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[spring事物传播机制 类型 描述 REQUIRED 支持当前事务，如果当前没有事务，就新建一个事物。这是最常见，默认的选择。 SUPPORTS 支持当前事务，如果当前没有事务，就以非事物方式执行。 MANDATORY 支持当前事务，如果当前没有事务，就跑出异常。 REQUIRES_NEW 新建事务，如果当前存在事务，就把当前事务挂起，开始新建事务。 NOT_SUPPORTED 以非事务方式执行， 如果当前存在事务，就把当前事务挂起。 NEVER 以非事务方式运行，如果当前存在事务，就跑出异常。 NESTED 如果当前存在事务，就嵌套在事务类执行，如果没有事务，就执行与REQUIRED类似的操作。 上面的描述都很清晰，除了NESTED，经过自己写代码测试，个人理解，NESTED在当前存在事务的时候，会在当前事务里面新建一个子事务，子事务回滚，父事务不一定会回滚（catch 了相应异常）；但是父事务回滚，NESTED新建的子事务也会回滚。 ⚠️ spring 事务是通过动态代理（切面）来实现的。所以在对象间调用方法时，Spring会将动态代理增强后的对象-代理类 注入到调用方，调用的方法是spring动态代理增强的具有事务管理功能的对象的方法，而在对象内部调用，spring 事务不会生效，因为调用的是没有被aop增强的原对象方法。 spring事务隔离级别 隔离级别 含义 DEFAULT 使用数据库默认的隔离级别 READ_UNCOMMITTED 允许读取尚未提交的更改。可能导致脏读、幻影读或不可重复读。 READ_COMMITTED 允许从已经提交的并发事务读取。可防止脏读，但幻影读和不可重复读仍可能会发生。 REPEATABLE_READ 可重复读，在事务里，每次读取数据的结果都一样，不管其他事务的结果有没有提交。可能会造成幻读。MySQL默认的隔离级别 SERIALIZABLE 串行化，一个事务提交前，其他事物将被挂起。就是说，在同一时间只有一个事务操作表。 分布式事务分布式事务是指操作多个数据库之间的事务，spring的org.springframework.transaction.jta.JtaTransactionManager，提供了分布式事务支持。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;groupId&gt;com.example&lt;/groupId&gt; &lt;artifactId&gt;distributed-transcation&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;distributed-transcation&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;tk.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mapper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.15&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-jta-atomikos&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.9&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 数据库及事务配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114@EnableTransactionManagement(proxyTargetClass = true)@Configuration@Slf4j@MapperScan(basePackages = "com.example.distributedtranscation.db2mapper",sqlSessionFactoryRef = "SqlSessionFactory2")public class DataSourceAndSqlSessionConfig &#123; @Bean("db1") public DataSource dataSourceOne(DatabaseProperties.DatabaseOneProperties databaseOneProperties) throws Exception &#123; AtomikosDataSourceBean atomikosDataSourceBean = new AtomikosDataSourceBean(); MysqlXADataSource mysqlXADataSource = new MysqlXADataSource(); mysqlXADataSource.setUrl(databaseOneProperties.getUrl()); mysqlXADataSource.setPinGlobalTxToPhysicalConnection(true); mysqlXADataSource.setUser(databaseOneProperties.getUsername()); mysqlXADataSource.setPassword(databaseOneProperties.getPassword()); atomikosDataSourceBean.setXaDataSource(mysqlXADataSource); atomikosDataSourceBean.setUniqueResourceName("one"); atomikosDataSourceBean.setMinPoolSize(databaseOneProperties.getMinPoolSize()); atomikosDataSourceBean.setMaxPoolSize(databaseOneProperties.getMaxPoolSize()); atomikosDataSourceBean.setBorrowConnectionTimeout(databaseOneProperties.getBorrowConnectionTimeout()); atomikosDataSourceBean.setLoginTimeout(databaseOneProperties.getLoginTimeout()); atomikosDataSourceBean.setMaintenanceInterval(databaseOneProperties.getMaintenanceInterval()); atomikosDataSourceBean.setMaxIdleTime(databaseOneProperties.getMaxIdleTime()); atomikosDataSourceBean.setTestQuery(databaseOneProperties.getTestQuery()); return atomikosDataSourceBean; &#125; @Bean(name = "db2") public DataSource dataSourceTwo(DatabaseProperties.DatabaseTwoProperties databaseTwoProperties) throws Exception &#123; AtomikosDataSourceBean atomikosDataSourceBean = new AtomikosDataSourceBean(); MysqlXADataSource mysqlXADataSource = new MysqlXADataSource(); mysqlXADataSource.setUrl(databaseTwoProperties.getUrl()); mysqlXADataSource.setPinGlobalTxToPhysicalConnection(true); mysqlXADataSource.setUser(databaseTwoProperties.getUsername()); mysqlXADataSource.setPassword(databaseTwoProperties.getPassword()); atomikosDataSourceBean.setXaDataSource(mysqlXADataSource); atomikosDataSourceBean.setUniqueResourceName("two"); atomikosDataSourceBean.setMinPoolSize(databaseTwoProperties.getMinPoolSize()); atomikosDataSourceBean.setMaxPoolSize(databaseTwoProperties.getMaxPoolSize()); atomikosDataSourceBean.setBorrowConnectionTimeout(databaseTwoProperties.getBorrowConnectionTimeout()); atomikosDataSourceBean.setLoginTimeout(databaseTwoProperties.getLoginTimeout()); atomikosDataSourceBean.setMaintenanceInterval(databaseTwoProperties.getMaintenanceInterval()); atomikosDataSourceBean.setMaxIdleTime(databaseTwoProperties.getMaxIdleTime()); atomikosDataSourceBean.setTestQuery(databaseTwoProperties.getTestQuery()); return atomikosDataSourceBean; &#125; @Bean("db1Manager") public DataSourceTransactionManager db1Manager(@Qualifier("db1") DataSource db) &#123; return new DataSourceTransactionManager(db); &#125; @Bean("db2Manager") public DataSourceTransactionManager db2Manager(@Qualifier("db2") DataSource db) &#123; return new DataSourceTransactionManager(db); &#125; @Bean("userTransaction") public UserTransaction userTransaction() throws Exception &#123; UserTransactionImp userTransactionImp = new UserTransactionImp(); userTransactionImp.setTransactionTimeout(1000); return userTransactionImp; &#125; @Bean(value = "userTransactionManager", initMethod = "init", destroyMethod = "close") public UserTransactionManager userTransactionManager() throws Exception &#123; UserTransactionManager userTransactionManager = new UserTransactionManager(); userTransactionManager.setForceShutdown(false); return userTransactionManager; &#125; @Bean("jtaManager") public JtaTransactionManager jtaTransactionManager(@Autowired UserTransactionManager userTransactionManager, @Autowired UserTransaction userTransaction) &#123; return new JtaTransactionManager(userTransaction, userTransactionManager); &#125; @Bean("SqlSessionFactory1") public SqlSessionFactory db1Sql(@Qualifier("db1") DataSource db) throws Exception &#123; return createSqlSession(db, "classpath:/db1xml/*.xml"); &#125; @Bean("SqlSessionFactory2") public SqlSessionFactory db2Sql(@Qualifier("db2") DataSource db) throws Exception &#123; return createSqlSession(db, "classpath:/db2xml/*.xml"); &#125; @Bean public SqlSessionTemplate createSqlTemplate1(@Qualifier("SqlSessionFactory1") SqlSessionFactory sqlSessionFactory) &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; @Bean public SqlSessionTemplate createSqlTemplate2(@Qualifier("SqlSessionFactory2") SqlSessionFactory sqlSessionFactory) &#123; return new SqlSessionTemplate(sqlSessionFactory); &#125; private static SqlSessionFactory createSqlSession(DataSource db, String path) throws Exception &#123; SqlSessionFactoryBean factoryBean = new SqlSessionFactoryBean(); factoryBean.setDataSource(db); org.apache.ibatis.session.Configuration configuration = new org.apache.ibatis.session.Configuration(); configuration.setMapUnderscoreToCamelCase(true); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); factoryBean.setMapperLocations(resolver.getResources(path)); factoryBean.setConfiguration(configuration); return factoryBean.getObject(); &#125;&#125; demo]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>spring</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[itext-pdf]]></title>
    <url>%2F2019%2F04%2F10%2Fitext-pdf%2F</url>
    <content type="text"><![CDATA[iText 基础基础介绍iText是著名的开放源码的站点sourceforge一个项目，是用于生成PDF文档的一个java类库。通过iText不仅可以生成PDF或rtf的文档，而且可以将XML、Html文件转化为PDF文件。本文仅讨论如何使用iTextApi生成PDF文件，不讨论关于xml，html相关的pdf转换特性。 基础APIiText DocumentDocument是iText中一个通用的文档类，所有我本内容最终都会被附加或者说填充到一个文档中，此文档对象也会在子元素被添加的同时回调一些由listener指定的回调接口！ 注意 当一个文档对象创建完成得到实例之后，我们就可以为这个文档实例添加一些元数据，比如文档所属用户，文档简要描述等等。 当一个文档对象创建完成得到实例之后，我们可以为文档指定文档页眉和页脚 只有先打开文档(调用document.open())之后我们才能够向文档中写入内容 打开文档之前，需要使用一个DocumentWriter的实现类比如PdfWriter的实例来将Document和一个OutputStream绑定到一起，当调用close()方法，文档内容将被写入到输出流中 一旦文档被打开，将无法再向文档中添加元数据 如果你在某一页面调整了页眉或者页脚，接下来的后续页面都会被改变 一旦文档被关闭，与当前文档关联的所有listener也都将被关闭核心API12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class Document implements DocListener, IAccessibleElement &#123; /** * Methods extended from DocListener */ public void open(); //打开文档 public void close(); //关闭万恶的囊 public boolean newPage(); //开始新的一页 public boolean setPageSize(Rectangle pageSize); //设置文档页面大小 public boolean setMargins(float marginLeft, float marginRight, float marginTop, float marginBottom); //设置文档页面边距 public void setPageCount(int pageN); //设置文档页码 public void resetPageCount(); //重置当前文档页码为0 /** * Fields declared document itself */ protected ArrayList&lt;DocListener&gt; listeners = new ArrayList&lt;&gt;(); //关联的listener protected boolean open; //文档是否已被打开 protected boolean close; //文档是否已被关闭 protected Rectangle pageSize; //文档页面大小 protected float marginLeft = 0; //文档左边距 protected float marginRight = 0; //文档右边距 protected float marginTop = 0; //文档上边距 protected float marginBottom = 0; //文档下边距 /** * Constructor method */ public Document(); //same as Document(PageSize.A4); A4 = new RectangleReadOnly(595,842) public Document(Rectangle pageSize); //same as Document(pageSize, 36, 36, 36, 36) public Document(Rectangle pageSize, float marginLeft, float marginRight,float marginTop, float marginBottom); /** * Methods declared document itself */ public void addDocListener(DocListener listener); public void removeDocListener(DocListener listener); public boolean add(Element element); public boolean addHeader(String name, String content); //为文档添加一个header public boolean addTitle(String title); //为文档添加一个title public boolean addSubject(String subject); //为文档添加一个主题 public boolean addKeywords(String keywords); //为文档添加一系列关键字 public boolean addAuthor(String author); //添加文档的作者 public boolean addCreator(String creator); //添加文档创建者名称 public boolean addCreationDate(); //设定文档创建时间，即当前时间&#125; 实例代码12345678910111213141516171819202122232425public class DocumentApiTest&#123; public static void main(String[] args) throws Exception &#123; //创建一个空白文档，无参构造函数相当于new Document(PageSize.A4,36,36,36,36) Document document = new Document(); //创建一个输出流，此处我们使用文件输出流 OutputStream outputStream = new FileOutputStream(new File("helloWorld.pdf")); //将目标文档同输出流绑定到一起 PdfWriter.getInstance(document , outputStream); //设置文档元数据 document.addAuthor("San Zhang"); document.addSubject("Test for Document Api!"); //打开文档 document.open(); //添加内容 document.add(new Paragraph("Hello world！")); //关闭文档 document.close(); &#125;&#125; iText Element文本元素的通用接口。 核心API1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public interface Element&#123; int type(); //当前元素类型 boolean isContent(); //当前元素是否是一个content object boolean isNestable(); //当前元素是否可以被嵌入到其他元素中 List&lt;Chunk&gt; getChunks(); //获取当前元素全部的chunks /** * 对type的诸多常量定义 */ int HEADER = 0; int TITLE = 1; int TITLE = 1; int SUBJECT = 2; int KEYWORDS = 3; int AUTHOR = 4; int PRODUCER = 5; int CREATIONDATE = 6; int CREATOR = 7; int LANGUAGE = 8; int CHUNK = 10; int PHRASE = 11; int PARAGRAPH = 12; int SECTION = 13; int LIST = 14; int LISTITEM = 15; int CHAPTER = 16; int ANCHOR = 17; int PTABLE = 23; int ANNOTATION = 29; int RECTANGLE = 30; int JPEG = 32; int JPEG2000 = 33; int IMGRAW = 34; int IMGTEMPLATE = 35; int JBIG2 = 36; int DIV = 37; int BODY = 38; int MARKED = 50; int YMARK = 55; int ALIGN_UNDEFINED = -1; //段落对齐方式：同ALIGN_LEFT int ALIGN_LEFT = 0; //段落水平左对齐 int ALIGN_CENTER = 1; //段落水平居中对其 int ALIGN_RIGHT = 2; //段落属性右对齐 int ALIGN_JUSTIFIED = 3; //段落水平展开，除了最后一行，其余各行水平伸展占据整行 int ALIGN_TOP = 4; //段落垂直靠顶部对齐 int ALIGN_MIDDLE = 5; //段落垂直居中对齐 int ALIGN_BOTTOM = 6; //段落处置靠底部对齐 int ALIGN_BASELINE = 7; //段落靠基线对齐 int ALIGN_JUSTIFIED_ALL = 8; //段落水平展开，各行均水平伸展占据整行&#125; iText Chunk可以被添加到文档中的最小的文本单位。许多其他元素都被拆分成一个或多个Chunk，每一个Chunk都关联了一个字符串以及对应的字体。关于chunk的布局参数等则应该在被拆分的元素内部进行定义。 核心API12345678910public class Chunk implements Element, IAccessibleElement &#123; protected StringBuffer content; //关联的文本内容 protected Font font; //关联的字体 public Chunk(); public Chunk(final char c); public Chunk(final char c, final Font font); public Chunk(final String content); public Chunk(final String content, final Font font);&#125; 示例代码12345678910111213public class ChunkApiTest&#123; public static void main(String[] args)&#123; //... Chunk chunk = new Chunk( "Hello world", FontFactory.getFont(FontFactory.COURIER, 20, Font.ITALIC, new BaseColor(255, 0,0)) ); document.add(chunk); //... &#125;&#125; iText Phrase一个Phrase是一系列Chunk的集合。每一个Phrase都有一个主字体，所有添加到此Phrase中的Chunk都默认使用这个字体，但是每一个Chunk仍然可以自定义字体。所有的Chunk使用同一个leading（行间距） 核心API12345678910111213141516171819202122public class Phrase extends ArrayList&lt;Element&gt; implements TextElementArray &#123; protected float leading; protected float multipliedLeading; protected Font font; public Phrase(); //same as Phrase(16); public Phrase(final float leading); public Phrase(final Chunk chunk); public Phrase(final float leading, final Chunk chunk); public Phrase(final String string); //Phrase(Float.NaN, string, new Font()) public Phrase(final String string, final Font font); //Phrase(Float.NaN, string, font) public Phrase(final float leading, final String string); //Phrase(leading, string, new Font()) public Phrase(final float leading, final String string, final Font font); public int type() &#123; return Element.PHRASE; &#125; public boolean add(final String s); public boolean add(final Element element); protected boolean addChunk(final Chunk chunk);&#125; 示例代码123456789101112131415161718192021public class PhraseApiTest&#123; public static void main(String[] args)&#123; //... // When no parameters are passed, the default leading = 16 Phrase phrase0 = new Phrase(); Phrase phrase1 = new Phrase("this is a phrase"); // In this example the leading is passed as a parameter Phrase phrase2 = new Phrase(16, "this is a phrase with leading 16"); // When a Font is passed (explicitly or embedded in a chunk), the default leading = 1.5 * size of the font Phrase phrase3 = new Phrase("this is a phrase with a red, normal font Courier, size 12", FontFactory.getFont(FontFactory.COURIER, 12, Font.NORMAL, new Color(255, 0, 0))); Phrase phrase4 = new Phrase(new Chunk("this is a phrase")); Phrase phrase5 = new Phrase(18, new Chunk("this is a phrase", FontFactory.getFont(FontFactory.HELVETICA, 16, Font.BOLD, new Color(255, 0, 0)))); //document.add(...) //... &#125;&#125; iText BaseColoriText 颜色工具类 核心API12345678910111213141516171819202122232425262728public class BaseColor &#123; //rgba值 private int value; //构造函数 public BaseColor(final int red, final int green, final int blue, final int alpha); public BaseColor(final int red, final int green, final int blue); //默认 alpha 为100,即完全不透明 public int getRGB(); public int getRed(); public int getGreen(); public int getBlue(); public int getAlpha(); //颜色常量 public static final BaseColor WHITE = new BaseColor(255, 255, 255); public static final BaseColor LIGHT_GRAY = new BaseColor(192, 192, 192); public static final BaseColor GRAY = new BaseColor(128, 128, 128); public static final BaseColor DARK_GRAY = new BaseColor(64, 64, 64); public static final BaseColor BLACK = new BaseColor(0, 0, 0); public static final BaseColor RED = new BaseColor(255, 0, 0); public static final BaseColor PINK = new BaseColor(255, 175, 175); public static final BaseColor ORANGE = new BaseColor(255, 200, 0); public static final BaseColor YELLOW = new BaseColor(255, 255, 0); public static final BaseColor GREEN = new BaseColor(0, 255, 0); public static final BaseColor MAGENTA = new BaseColor(255, 0, 255); public static final BaseColor CYAN = new BaseColor(0, 255, 255); public static final BaseColor BLUE = new BaseColor(0, 0, 255);&#125; iText BaseFontBaseFont为iText字体基类，可根据自体文件创建或加载对应字体。 核心API1234public abstract class BaseFont&#123; public static BaseFont createFont(); //创建一个基于默认字体Helvetica的自体，且不嵌入 public static BaseFont createFont(String name, String encoding, boolean embedded); //按照指定自体文件名称加载自体文件，并创建字体&#125; 示例代码1234567public class BaseFontApiTest&#123; public static void main(String[] args)&#123; String MSYH_FONT_STR = "msyh.ttf"; //加载系统classPath路径下的由文件名msyh.ttf指定的微软雅黑字体 baseFontChinese = BaseFont.createFont(MSYH_FONT_STR, BaseFont.IDENTITY_H, false); &#125;&#125; 注意在使用maven等包管理工具管理项目时，一般我们会将字体等资源文件放到项目的resources资源文件目录，在项目的打包阶段，maven编译插件通常会对资源文件进行编译，这会导致字体文件被损坏，若要保证自体文件的正常使用，请设置插件的filtering为false123456789101112131415&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;!--省略部分无关代码--&gt; &lt;build&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;src/main/resources&lt;/directory&gt; &lt;includes&gt; &lt;include&gt;**/*.tty&lt;/include&gt; &lt;/includes&gt; &lt;filtering&gt;false&lt;/filtering&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;/build&gt;&lt;/project&gt; iText Font一个字体描述类，包含字体类型，大小，样式以及颜色 核心API1234567891011121314151617181920212223242526272829303132333435public class Font implements Comparable&lt;Font&gt; &#123; //内部枚举，字体样式 public enum FontStyle &#123; NORMAL("normal"), BOLD("bold"), ITALIC("italic"), OBLIQUE("oblique"), UNDERLINE("underline"), LINETHROUGH("line-through"); private String code; FontStyle(final String code) &#123; this.code = code; &#125; /** * @return a string, the text value of this style. * @since 5.0.6 */ public String getValue() &#123; return code; &#125; &#125; private float size; private int style; private BaseColor color; private BaseFont baseFont; /** * 构造函数 */ public Font(final BaseFont bf, final float size, final int style, final BaseColor color);&#125; 示例代码123456789public class FontApiTest &#123; public static void main(String[] args)&#123; BaseColor fontColor = new BaseColor(0x59, 0x57, 0x57, 0xff); int fontSize = 8; int fontStyle = Font.NORMAL; BaseFont baseFontChinese = BaseFont.createFont(MSYH_FONT_STR, BaseFont.IDENTITY_H, false); Font chineseFont = new Font(baseFontChinese, fontSize, fontStyle, fontColor); &#125;&#125; iText RectangleRectangle是对一个矩形区域的抽象。 核心API123456789101112131415161718192021222324252627282930313233343536public class Rectangle implements Element &#123; protected float llx; //矩形左下角x位置（lower left x-coordinate） protected float lly; //矩形左下角y位置（lower left y-coordinate） protected float urx; //矩形右上角x位置（upper right x-coordinate） protected float ury; //矩形右上角y位置（upper right y-coordinate） protected int rotation; //矩形旋转角度(是角度不是弧度) protected BaseColor backgroundColor; //矩形背景颜色 protected int border; //当前矩形是否有边框，比如如果等于3（TOP | BOTTOM），表示有上下边框 public static final int UNDEFINED = -1; //未定义是否有Border public static final int TOP = 1; //当前矩形有上边框 public static final int BOTTOM = 2; //当前矩形有下边框 public static final int LEFT = 4; //当前矩形有左边框 public static final int RIGHT = 8; //当前矩形有右边框 public static final int NO_BORDER = 0; //当前矩形没有任何边框 public static final int BOX = TOP + BOTTOM + LEFT + RIGHT; //当前矩形有上下左右边框 protected float borderWidth; //矩形边框宽度 protected float borderWidthLeft; protected float borderWidthRight; protected float borderWidthTop; protected float borderWidthBottom; protected BaseColor borderColor; //矩形边框颜色 protected BaseColor borderColorLeft; protected BaseColor borderColorRight; protected BaseColor borderColorTop; protected BaseColor borderColorBottom; public Rectangle(final float urx, final float ury); //with default llx=0 and lly = 0 and rotate=0 public Rectangle(final float llx, final float lly, final float urx, final float ury); //with default rotate=0 public Rectangle(final float llx, final float lly, final float urx, final float ury, final int rotation); &#125; iText PdfPCelliText单元格。是PdfPTable的基本元素。关于单元格的设计可以参考html的盒子模型。之后所有的控件都是由PdfPCell扩展而来。具体细节之后会详述。 核心API123456789101112131415161718192021222324252627282930313233343536373839404142public class PdfPCell extends Rectangle implements IAccessibleElement &#123; private ColumnText column; private int verticalAlignment; //当前单元格竖直方向对齐格式 private float paddingLeft; //单元格内边距，默认均为2 private float paddingRight; private float paddingTop; private float paddingBottom; private float fixedHeight; //单元格高度 private float calculatedHeight; //单元格高度 private float minimumHeight; //单元格最小高度 private float cachedMaxHeight; private boolean noWrap; //单元格是否对内容进行包裹，如果true且内容较多，会换行显示。如果为false会对内容进行截断。 private PdfPTable table; //附属的表格 private int colspan = 1; //当前单元格占据表格的列数 private int rowspan = 1; //当前单元格占据表格的行数 private Image image; private PdfPCellEvent cellEvent; //当前单元格关联的单元格布局函数 protected Phrase phrase; //单元格内容 private int rotation; //单元格旋转角度 可选值0,90,180,270 public PdfPCell(); //构造函数 public PdfPCell(Phrase phrase); public PdfPCell(Image image); public PdfPCell(Image image, boolean fit); public void setColspan(int colspan); //设置单元格占据的列 public void setRowspan(int rowspan); //设置单元格占据的行 public void setCellEvent(PdfPCellEvent cellEvent); //设置单元格布局实现 public void setNoWrap(boolean noWrap); //设置是否wrap public void setFixedHeight(float fixedHeight); //设置单元格固定高度 public void setLeading(float fixedLeading, float multipliedLeading); //leading = fixedLeading + multipliedLeading * maxFontSize &#125; 注意如果某个表格被拆分为多列，比如列数为columnCountOfTable，如果最后一行中所有单元格的列数加起来都不足columnCountOfTable，那么这一行内的单元格将不会被展示出来。如果想让单元格展示出来，必须利用一些空白单元格对最后一行进行补齐。 示例代码1234567891011121314151617public class PdfPCellApiTest&#123; public static void main(String[] args)&#123; //... PdfPTable mainFrame = new PdfPTable(12); //the table will be split to 12 columns PdfPCell oneColumnCell; int cellCount = 12; //if set cellCount=11,no cell will be shown. for (int index = 0;index &lt; cellCount;index ++)&#123; oneColumnCell = new PdfPCell(new Phrase(new Chunk("cell " + index))); oneColumnCell.setColspan(1); mainFrame.add(oneColumnCell); &#125; //... &#125;&#125; iText PdfPTableiText表格类，一个表格可以被给定一个绝对位置，也可以作为一个Element被放置到一个Document中，如果被放置到一个Document中，那么这个表格占据这个document除开上下左右边距之后的整个空间。在日常的项目实现中我们一般会使用表格来进行布局。参照bootstrap中的一些思想。我们一般会将表格框架拆分为12列或者是24列。具体为什么是12列或者24列，大家可以自己想一下。 核心APIPdfPTable包含的API众多，我们此处只罗列几个比较重要的。其实对于PdfPTable主要是理解为什么需要将其拆分为12列或者是24列，其他关于具体怎么使用它进行布局的部分实在是太过简单，毕竟流式布局实在没什么好说的。123456789101112public class PdfPTable implements LargeElement, Spaceable, IAccessibleElement &#123; protected ArrayList&lt;PdfPRow&gt; rows; //当前表格的行 protected float widthPercentage; //当前表格占据的宽度百分比 private boolean splitRows; //是否拆分页脚最后一个单元格（如果页面剩余宽度不够一个单元格的高度） private boolean splitLate ; public PdfPTable(final int numColumns); //构造函数指定表格列数目 public PdfPCell addCell(final PdfPCell cell); //向当前表格中添加一个单元格 public void setWidthPercentage(final float widthPercentage); //设置当前表格宽度百分比 public void setSplitRows(final boolean splitRows); public boolean isSplitLate();&#125; 示例代码1234567891011121314151617181920212223242526272829303132333435363738394041public class PdfPTableTest&#123; public static void main(String[] args)&#123; //... PdfPTable mainFrame = new PdfPTable(12); mainFrame.setWidthPercentage(100); PdfPCell oneColumnCell = new PdfPCell(new Phrase(new Chunk("one column cell"))); oneColumnCell.setColspan(1); PdfPCell twoColumnCell = new PdfPCell(new Phrase(new Chunk("two column cell"))); oneColumnCell.setColspan(2); PdfPCell threeColumnCell = new PdfPCell(new Phrase(new Chunk("three column cell"))); oneColumnCell.setColspan(3); PdfPCell fourColumnCell = new PdfPCell(new Phrase(new Chunk("four column cell"))); oneColumnCell.setColspan(4); PdfPCell sixColumnCell = new PdfPCell(new Phrase(new Chunk("six column cell"))); oneColumnCell.setColspan(6); //第一行，两个占据一列的单元格，两个占据两列的单元格，一个占据六列的单元格 mainFrame.addCell(oneColumnCell); mainFrame.addCell(oneColumnCell); mainFrame.addCell(twoColumnCell); mainFrame.addCell(twoColumnCell); mainFrame.addCell(sixColumnCell); //第二行，四个占据3列的单元格 mainFrame.addCell(threeColumnCell); mainFrame.addCell(threeColumnCell); mainFrame.addCell(threeColumnCell); mainFrame.addCell(threeColumnCell); //第三行，三个占据四列的单元格 mainFrame.addCell(fourColumnCell); mainFrame.addCell(fourColumnCell); mainFrame.addCell(fourColumnCell); &#125;&#125; iText控件扩展前面也提到过，对于iText,想要进行控件实现，那么就必须依赖于PdfPCell类以及PdfPCellEvent。 PdfPCellEvent接口定义12345678910111213141516public interface PdfPCellEvent &#123; /** * 此方法在单元格整个渲染流程的最后面被执行，普通的文本或者是复杂的图片将会通过由canvases指定的四种画布勾画到具体单元格中。四种画布索引如下： * 1）PdfPTable.BASECANVAS：最原始的画布，所有勾画到这个画布内容都会被置于单元格最底层 * 2）PdfPTable.BACKGROUNDCANVAS：背景画布，所有勾画到这个画布的内容都会被置于背景层 * 3）PdfPTable.LINECANVAS ：线画布，所有勾画到这个画布的内容都会被置于线层 * 4）PdfPTable.TEXTCANVAS：文字画布，所有勾画到这个画布的内容都会被置于文字层，文字层是在单元格的最上层 * 上述画布层按照指定属性依次在前一个画布的上层 * * 三个参数: * cell:当前单元格 * position: 当前单元格所处位置 * canvases：四种画布 */ void cellLayout(PdfPCell cell, Rectangle position, PdfContentByte[] canvases);&#125; How to example本例中我们将会使用一个比较复杂的例子来讲述具体如何通过扩展PdfPCell来得到一个控件，这个控件的名称叫南丁格尔玫瑰图，不知道什么是南丁格尔玫瑰图的同学可以看百度一下。下面是南丁格尔玫瑰图的报读百科描述。 南丁格尔玫瑰图是弗罗伦斯·南丁格尔所发明的。又名为极区图 。是一种圆形的直方图。 南丁格尔自己常昵称这类图为鸡冠花图（coxcomb），并且用以表达军医院季节性的死亡率，对象是那些不太能理解传统统计报表的公务人员。 弗罗伦斯·南丁格尔 （英语：Florence Nightingale，1820年5月12日－1910年8月13日），英国护士和统计学家，出生于意大利的一个英国上流社会的家庭。在德国学习护理后，曾往伦敦的医院工作。于1853年成为伦敦慈善医院的护士长。 出于对资料统计的结果会不受人重视的忧虑，她发展出一种色彩缤纷的图表形式，让数据能够更加让人印象深刻。 这种图表形式有时也被称作「南丁格尔的玫瑰」，是一种圆形的直方图。 南丁格尔自己常昵称这类图为鸡冠花图（coxcomb），并且用以表达军医院季节性的死亡率，对象是那些不太能理解传统统计报表的公务人员。 她的方法打动了当时的高层，包括军方人士和维多利亚女王本人，于是医事改良的提案才得到支持。 接下来我会一步一步的展示如何实现这个控件。 注意事项 由于PdfPCell有一些基本的样式属性，其中一些属性比如border相关的我们需要禁用，为什么呢，因为通常我们控件的border会靠内一点，即我们会留出一点padding，这样当吧单元格放到表格中时不至于挤到一起。我们通过设置pdfPCell.border = Rectangle.NO_BORDER来禁用。 除了border相关的属性，还有一个就是单元格自带的backgroundColor属性,像上一点所说我们要使得控件展示出来时不至于挤到一起，会在padding的部分留白，但PdfPCell的默认backgroundColor是覆盖这一部分的。需求定义控件基本属性 编码第一步，控件基本骨架前面也提到过，想要扩展控件，那么我们必须使用PdfPCell以及PdfPCellEvent这两个类，让我们的控件继承自PdfPCell并实现PdfPCellEvent，在PdfPCellEvent的doCellLayout回调中进行我们的控件勾画工作。1234567891011121314/** * 南丁格尔玫瑰图 * * @author wenchao */public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; public NightingaleRoseDiagram() &#123; &#125; @Override public void cellLayout(PdfPCell cell, Rectangle position, PdfContentByte[] canvases) &#123; //draw component content here &#125;&#125; 第二步，控件基本属性“禁用”根据前面注意事项所说，我们需要“禁用”边框以及背景色两个属性1234567891011121314151617181920212223/** * 南丁格尔玫瑰图 * * @author wenchao */public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; public NightingaleRoseDiagram() &#123; disableTheDefaultFeature(); &#125; @Override public void cellLayout(PdfPCell cell, Rectangle position, PdfContentByte[] canvases) &#123; &#125; /** * 禁用控件自定义边框以及背景色 */ private void disableTheDefaultFeature()&#123; this.setBorder(PdfPCell.NO_BORDER); this.setBackgroundColor(BaseColor.WHITE); &#125;&#125; 第三步，定义控件基本属性南丁格尔玫瑰图内部是由扇区定义的，在笔者接触到的南丁格尔玫瑰图中这些扇区都是等分的，所以今天实现的南丁格尔玫瑰图扇区也会是等分的。 单元格背景色 待勾画控件以圆形或者圆环为基础框架，所以需要定义圆心（圆心在cellLayout回调中使用position确定），最大半径，最小半径。 具体有多少个扇区，由传入的扇区数据集合大小来确定 扇区基本数据,扇区半径，扇区背景色，扇区描述（扇区描述文字，扇区描述字体） 单元格高度，我们设定为最大圆半径 × 2 × 1.2 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485/** * 南丁格尔玫瑰图 * * @author wenchao */public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; private BaseColor bgColor; private static final float DEFAULT_HEIGHT_EXPAND_RATIO = 1.2f; private float innerRadius; private static final float MIN_INNER_RADIUS = 0; private static final float MAX_INNER_RADIUS_RATIO = 0.8f; private float outerRadius; private static final float MIN_OUTER_RADIUS = 50; private static final float MAX_OUTER_RADIUS = 80; private List&lt;RoseDiagramItem&gt; roseDiagramItems; public NightingaleRoseDiagram(BaseColor bgColor, float outerRadius, float innerRadius, List&lt;RoseDiagramItem&gt; roseDiagramItems) &#123; this.bgColor = bgColor; this.outerRadius = normalize(outerRadius,MIN_OUTER_RADIUS,MAX_OUTER_RADIUS); this.innerRadius = normalize(innerRadius,MIN_INNER_RADIUS,MAX_INNER_RADIUS_RATIO * this.outerRadius); this.roseDiagramItems = roseDiagramItems; for (RoseDiagramItem roseDiagramItem:roseDiagramItems)&#123; roseDiagramItem.normalize(this.innerRadius,this.outerRadius); &#125; this.setFixedHeight(this.outerRadius * 2 * DEFAULT_HEIGHT_EXPAND_RATIO); disableTheDefaultFeature(); &#125; @Override public void cellLayout(PdfPCell cell, Rectangle position, PdfContentByte[] canvases) &#123; &#125; /** * 禁用控件自定义边框以及背景色 */ private void disableTheDefaultFeature() &#123; this.setBorder(PdfPCell.NO_BORDER); this.setBackgroundColor(BaseColor.WHITE); &#125; public static class RoseDiagramItem &#123; private String description; private Font descriptionFont; private float radius; private BaseColor bgColor; public RoseDiagramItem(String description, Font descriptionFont, float radius, BaseColor bgColor) &#123; this.description = description; this.descriptionFont = descriptionFont; this.radius = radius; this.bgColor = bgColor; &#125; public void normalize(float innerRadius,float outerRadius)&#123; this.radius = NightingaleRoseDiagram.normalize(radius,innerRadius,outerRadius); &#125; &#125; /** * 按照最大最小值对指定半径做处理 * @param radius 当前半径 * @param minRadius 最小半径 * @param maxRadius 最大半径 * @return 如果当前半径小于最小半径，返回最小半径，如果当前半径大于最大半径，返回最大半径，否则返回当前半径 */ private static float normalize(float radius, float minRadius, float maxRadius) &#123; if (radius &lt; minRadius)&#123; return minRadius; &#125; if (radius &gt; maxRadius)&#123; return minRadius; &#125; return radius; &#125;&#125; 第四步，勾画控件123456789101112131415161718192021222324252627282930313233343536/** * 南丁格尔玫瑰图 * * @author wenchao */public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; //... @Override public void cellLayout(PdfPCell cell, Rectangle position, PdfContentByte[] canvases) &#123; //按照单元格宽度进行伸缩 float oldOuterRadius = outerRadius; outerRadius = Math.min(outerRadius,position.getWidth() / 2 - 20); innerRadius = Math.min(innerRadius,MAX_INNER_RADIUS_RATIO * this.outerRadius); for (RoseDiagramItem roseDiagramItem : roseDiagramItems) &#123; roseDiagramItem.scale(outerRadius / oldOuterRadius); &#125; //勾画背景色 drawBackGround(position, canvases[PdfPTable.BACKGROUNDCANVAS], bgColor); //勾画外围圆以及网格刻度线 drawOuterCircle(position, canvases[PdfPTable.BACKGROUNDCANVAS], outerRadius, roseDiagramItems.size()); //勾画扇区 drawSectors(position, canvases[PdfPTable.BACKGROUNDCANVAS], roseDiagramItems); //勾画扇区描述 drawSectorsDesc(position, canvases[PdfPTable.TEXTCANVAS], roseDiagramItems); //勾画内部圆 drawInnerCircle(position, canvases[PdfPTable.BACKGROUNDCANVAS], innerRadius); &#125; //..&#125; 第五步，勾画背景勾画单元格背景时，我们使用padding缩小一点勾画的范围，就可以预留出一点空白，避免单元格挤到一起1234567891011121314151617181920212223public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; //... private void drawBackGround(Rectangle position, PdfContentByte canvas, BaseColor bgColor) &#123; Rectangle backgroundRectangle = new Rectangle(position); //预留空白padding backgroundRectangle.setLeft(backgroundRectangle.getLeft() + DEFAULT_PADDING); backgroundRectangle.setRight(backgroundRectangle.getRight() - DEFAULT_PADDING); backgroundRectangle.setBottom(backgroundRectangle.getBottom() + DEFAULT_PADDING); backgroundRectangle.setTop(backgroundRectangle.getTop() - DEFAULT_PADDING); //勾画背景 canvas.saveState(); canvas.setLineWidth(0); canvas.setColorStroke(bgColor); canvas.setColorFill(bgColor); canvas.rectangle(backgroundRectangle.getLeft(), backgroundRectangle.getBottom(), backgroundRectangle.getWidth(), backgroundRectangle.getHeight()); canvas.closePathFillStroke(); canvas.restoreState(); &#125; //...&#125; 示例 第五步勾画刻度1234567891011121314151617181920212223242526272829303132public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; //... private void drawOuterCircle(Rectangle position, PdfContentByte canvas, float outerRadius, int sectorCount) &#123; float centerX = (position.getLeft() + position.getRight()) / 2; float centerY = (position.getBottom() + position.getTop()) / 2; int defaultScale = 5; //以五为级别勾画刻度 canvas.saveState(); canvas.setColorStroke(BaseColor.WHITE); canvas.setLineWidth(0.1); for (int index = 0; index &lt; defaultScale; index++) &#123; canvas.circle(centerX, centerY, outerRadius * (index + 1) / defaultScale); canvas.stroke(); &#125; float sectorAngleOffset = (float) (Math.PI * 2); double sectorIncrement = Math.PI * 2 / sectorCount; for (int index = 0; index &lt; sectorCount; index++) &#123; canvas.moveTo(centerX, centerY); canvas.lineTo( centerX + outerRadius * Math.cos(sectorAngleOffset), centerY + outerRadius * Math.sin(sectorAngleOffset) ); sectorAngleOffset += sectorIncrement; canvas.stroke(); &#125; canvas.restoreState(); &#125; //...&#125; 示例 第六步，勾画扇区描述123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; //... private void drawSectorsDesc(Rectangle position, PdfContentByte canvas, List&lt;RoseDiagramItem&gt; roseDiagramItems) &#123; float centerX = (position.getLeft() + position.getRight()) / 2; float centerY = (position.getBottom() + position.getTop()) / 2; double expand = 10; double sectorIncrement = Math.PI * 2 / roseDiagramItems.size(); double sectorAngleOffset = sectorIncrement / 2 + (float) (Math.PI / 2); //扇区描述文字初始偏移量为扇区角度的一半 double sectorBoundCenterX; double sectorBoundCenterY; double sectorAngleCos; double sectorAngleSin; float descStrWidth; float descStrHeight; for (RoseDiagramItem roseDiagramItem : roseDiagramItems) &#123; sectorAngleCos = Math.cos(sectorAngleOffset); sectorAngleSin = Math.sin(sectorAngleOffset); sectorBoundCenterX = centerX + (outerRadius + expand) * sectorAngleCos; sectorBoundCenterY = centerY + (outerRadius + expand) * sectorAngleSin; descStrWidth = roseDiagramItem.descriptionFont.getBaseFont().getWidthPoint( roseDiagramItem.description, roseDiagramItem.descriptionFont.getSize() ); descStrHeight = roseDiagramItem.descriptionFont.getBaseFont().getWidthPoint( "AA", roseDiagramItem.descriptionFont.getSize() ); //如果是 if (sectorAngleCos &gt; 0) &#123; ColumnText.showTextAligned( canvas, Element.ALIGN_CENTER, new Phrase(new Chunk( roseDiagramItem.description, roseDiagramItem.descriptionFont )), (float) (sectorBoundCenterX + descStrWidth / 2), (float) (sectorBoundCenterY - descStrHeight / 2), 0 ); &#125; else if (sectorAngleCos &lt; 0) &#123; ColumnText.showTextAligned( canvas, Element.ALIGN_CENTER, new Phrase(new Chunk( roseDiagramItem.description, roseDiagramItem.descriptionFont )), (float) (sectorBoundCenterX - descStrWidth / 2), (float) (sectorBoundCenterY - descStrHeight / 2), 0 ); &#125; else &#123; // 不会出现等于0的情况 &#125; sectorAngleOffset += sectorIncrement; &#125; &#125; //...&#125; 示例 第七步，勾画扇区12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; //... private void drawSectors(Rectangle position, PdfContentByte canvas, List&lt;RoseDiagramItem&gt; roseDiagramItems) &#123; if (roseDiagramItems.isEmpty()) &#123; return; &#125; int sectorCount = roseDiagramItems.size(); float centerX = (position.getLeft() + position.getRight()) / 2; float centerY = (position.getBottom() + position.getTop()) / 2; float currentSectorAngleOffset = 90; float currentSectorAngle; BaseColor currentSectorBGColor; Point[] sectorVertices; canvas.saveState(); canvas.setLineWidth(0.1); //画出表示比例的扇区 for (RoseDiagramItem roseDiagramItem : roseDiagramItems) &#123; currentSectorAngle = 360f / sectorCount; currentSectorBGColor = roseDiagramItem.bgColor; sectorVertices = getSectorVertices(currentSectorAngleOffset, currentSectorAngle, centerX, centerY, roseDiagramItem.radius); canvas.setColorFill(currentSectorBGColor); canvas.setColorStroke(currentSectorBGColor); canvas.moveTo(sectorVertices[0].x, sectorVertices[0].y); for (int index = 1; index &lt; sectorVertices.length; index++) &#123; canvas.lineTo(sectorVertices[index].x, sectorVertices[index].y); &#125; canvas.closePathFillStroke(); currentSectorAngleOffset += currentSectorAngle; &#125; canvas.restoreState(); &#125; /** * 计算每一个扇区对应的顶点信息 * * @param currentSectorAngleOffset 扇区偏移角度 * @param currentSectorAngle 当前扇区角度 * @param centerXPosition 圆心x坐标 * @param centerYPosition 圆心y坐标 * @param radius 扇区半径 * @return 扇区对应顶点信息 */ private Point[] getSectorVertices( float currentSectorAngleOffset, float currentSectorAngle, float centerXPosition, float centerYPosition, float radius) &#123; //计算出画当前扇区需要的顶点的数目 int sectorVerticesCount = Math.round(currentSectorAngle / 360 * DEFAULT_CALC_STEP_COUNT + 0.5f) + 1; Point[] sectorVertices = new Point[sectorVerticesCount]; //初始化 for (int index = 0; index &lt; sectorVerticesCount; index++) &#123; sectorVertices[index] = new Point(0, 0); &#125; sectorVertices[0].x = centerXPosition; sectorVertices[0].y = centerYPosition; for (int index = 1; index &lt; sectorVerticesCount; index++) &#123; sectorVertices[index].x = (float) (centerXPosition + radius * Math.cos(currentSectorAngleOffset * Math.PI * 2 / 360 + (index - 1) * 1.0f / (sectorVerticesCount - 2) * currentSectorAngle * Math.PI * 2 / 360)); sectorVertices[index].y = (float) (centerYPosition + radius * Math.sin(currentSectorAngleOffset * Math.PI * 2 / 360 + (index - 1) * 1.0f / (sectorVerticesCount - 2) * currentSectorAngle * Math.PI * 2 / 360)); &#125; return sectorVertices; &#125; //...&#125; 示例 第八步，玫瑰图内圈123456789101112131415public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; //... private void drawInnerCircle(Rectangle position, PdfContentByte canvas, float innerRadius) &#123; float centerX = (position.getLeft() + position.getRight()) / 2; float centerY = (position.getBottom() + position.getTop()) / 2; canvas.saveState(); canvas.setLineWidth(0); canvas.setColorStroke(bgColor); canvas.circle(centerX,centerY,innerRadius); canvas.fillStroke(); canvas.restoreState(); &#125; //...&#125; 多个单元格展示 测试代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public class NightingaleRoseDiagram extends PdfPCell implements PdfPCellEvent &#123; public static void main(String[] args) throws Exception &#123; String destFileStr = "result/NightingaleRoseDiagram.pdf"; File destFile = new File(destFileStr); destFile.getParentFile().mkdirs(); Document document = new Document(); PdfWriter.getInstance(document, new FileOutputStream(destFile)); document.open(); int partCount = 8; String[] sectorsDesc = new String[]&#123;"A", "B", "C", "D", "E", "F", "G", "H"&#125;; float[] scoresValue = new float[]&#123;20, 100, 90, 40, 90, 30, 90, 70&#125;; BaseColor[] sectorsColors = new BaseColor[]&#123; new BaseColor(0xff016895), new BaseColor(0xffe30c81), new BaseColor(0xffd1dc2a), new BaseColor(0xffff841a), new BaseColor(0xff07a858), new BaseColor(0xff01adf9), new BaseColor(0xfff50100), new BaseColor(0xff960200) &#125;; Font font = new Font(BaseFont.createFont(), 8, Font.NORMAL, new BaseColor(0xff333333)); RoseDiagramItem roseDiagramItem; List&lt;RoseDiagramItem&gt; roseDiagramItems = new ArrayList&lt;&gt;(); for (int index = 0; index &lt; partCount; index++) &#123; roseDiagramItem = new RoseDiagramItem( sectorsDesc[index], font, scoresValue[index], sectorsColors[index] ); roseDiagramItems.add(roseDiagramItem); &#125; BaseColor diagramBgColor = new BaseColor(0xffe5e5e5); NightingaleRoseDiagram nightingaleRoseDiagram = new NightingaleRoseDiagram( diagramBgColor, 100, 5, roseDiagramItems ); PdfPTable mainFrame = new PdfPTable(12); mainFrame.setWidthPercentage(100); //单个单元格 nightingaleRoseDiagram.setColspan(12); mainFrame.addCell(nightingaleRoseDiagram); //多单元格 /*nightingaleRoseDiagram.setColspan(3); mainFrame.addCell(nightingaleRoseDiagram); mainFrame.addCell(nightingaleRoseDiagram); mainFrame.addCell(nightingaleRoseDiagram); mainFrame.addCell(nightingaleRoseDiagram);*/ document.add(mainFrame); document.close(); &#125;&#125; 结语本文只是简单的对iText的一些比较常用的API做了一些基本介绍。然后利用南丁格尔玫瑰图这个控件的实现来简单的介绍了一下一般如何在iText中扩展一个控件，当前这个南丁格尔玫瑰图的控件实现只是为了展示整个过程，要想实现一个高可用的控件，还需要考虑更多的情况。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>pdf</tag>
        <tag>itext</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty学习笔记]]></title>
    <url>%2F2019%2F04%2F03%2Fnetty%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Channel底层网络传输 API 必须提供给应用 I/O操作的接口，如读，写，连接，绑定等等。 ChannelHandler业务逻辑主要存活于此，主要子接口分别有ChannelInboundHandler，ChannelOutboundHandler。ChannelInboundHandler入站时回调主要处理入站逻辑，主要应用于解码器，获取客户端发送的数据等逻辑。相反ChannelOutboundHandler出站时回调处理出战逻辑，主要应用于编码逻辑，发送数据给客户端等逻辑。 ChannelInboundHandler 方法 描述 channelUnregistered channel从EventLoop注销时回调方法 channelRegistered 注册到EventLoop时回调方法 channelActive channel连接到远程端口可以接受和发送数据了时的回调方法 channelInactive channel 未连接到远程端口，或者连接中断回调 channelReadComplete channel读操作完成时回调 channelRead 数据准备好刻时回调 channelWritabilityChanged 当channel的可写状态发生改变时回调。用户可以确保写入速度不会太快（存在OutOfMemoryError的风险），或者可以在Channel可再次写入时恢复写入。Channel.isWritable（）可用于检测通道的实际可写性。可写性的阈值可以通过Channel.config（）。setWriteHighWaterMark（）和Channel.config（）。setWriteLowWaterMark（）来设置。 userEventTriggered 当用户调用了ChannelHandlerContext.fireUserEventTriggered回调（不会在当前的handler生效，后面的handler才会生效） 注意⚠️ 1.在 inBoundHandler 中调用了write （）方法，会直接把任务，交给该inBoundHandler 在ChannelPipeline中上面的outBoundHandler处理。 2.使用ReferenceCountUtil.release() 来丢弃收到的信息。 总结：如果消息是被 消耗/丢弃 并不会被传入下个 ChannelPipeline 的 ChannelOutboundHandler 或者ChannelInboundHandler，调用 ReferenceCountUtil.release(message) 。一旦消息经过实际的传输，在消息被写或者 Channel 关闭时，它将会自动释放。 ChannelOutboundHandler 方法 描述 bind 请求绑定channel到本地地址回调 connect channel连接到远程地址回调 disconnect channel从远程服务器上断开回调 close 关闭channel回调 deregister 取消channel在eventloop上的注册回调 read 在channel中读数据回调 flush flush数据到远程服务器 write 写数据到远程服务器 ChannelPipelineChannelHandler的容器，当Channel 创建时自动创建。ChannelHandler执行的顺序与添加到ChannelPipeline的顺序有关。具体就是ChannelInboundHandler顺序的，ChannelOutboundHandler时逆序的。 ChannelHandlerContext接口 ChannelHandlerContext 代表 ChannelHandler 和ChannelPipeline 之间的关联,并在 ChannelHandler 添加到 ChannelPipeline 时创建一个实例。ChannelHandlerContext 的主要功能是管理通过同一个 ChannelPipeline 关联的 ChannelHandler 之间的交互。 EventLoop&amp;EventLoopGroup用于处理channel i/o 操作的的线程 1.所有 EventLoop 从 EventLoopGroup 分配。每个新的 channel 将会获得新的 EventLoop 2.EventLoop 分配给 channel 用于执行所有事件和任务 3.Channel 绑定到 EventLoop。一个 channel 属于一个连接 ChannelFuture类似jdk中的future，但比jdk中的future 强大，可以调用addListener 方法添加channel完成io操作时的回调。 类似jdk中的future，但比jdk中的future 强大，可以调用addListener 方法添加channel完成io操作时的回调。 解码器解码器是一种 ChannelInboundHandler 的抽象实现。 主要分两类： 解码字节到消息（ByteToMessageDecoder 和 ReplayingDecoder） 解码消息到消息（MessageToMessageDecoder） 只需要实现decode ，decodeLast方法 编码器2种类型： message到message的编码(MessageToMessageEncoder) message到byte的编码(MessageToByteEncoder) 实现encode方法 解编码器2种类型： ByteToMessageCodec：message到byte的编解码 MessageToMessageCodec：message到message的编解码 实现encode,decode ，decodeLast方法 CombinedChannelDuplexHandler结合解码器和编码器在一起可能会牺牲可重用性。为了避免这种方式，并且部署一个解码器和编码器到 ChannelPipeline 作为逻辑单元而不失便利性。关键是下面的类: 1public class CombinedChannelDuplexHandler&lt;I extends ChannelInboundHandler,O extends ChannelOutboundHandler&gt; 空闲连接以及超时IdleStateHandler：如果连接闲置时间过长，则会触发 IdleStateEvent 事件。在 ChannelInboundHandler 中可以覆盖 userEventTriggered(…) 方法来处理 IdleStateEvent。 ReadTimeoutHandler：在指定的时间间隔内没有接收到入站数据则会抛出 ReadTimeoutException 并关闭 Channel。ReadTimeoutException 可以通过覆盖 ChannelHandler 的 exceptionCaught(…) 方法检测到。 WriteTimeoutHandler：WriteTimeoutException 可以通过覆盖 ChannelHandler 的 exceptionCaught(…) 方法检测到。 解码分隔符和基于长度的协议分隔符协议DelimiterBasedFrameDecoder：接收ByteBuf由一个或多个分隔符拆分，如NUL或换行符 LineBasedFrameDecoder：接收ByteBuf以分割线结束，如”\n”和”\r\n” 基于长度的协议FixedLengthFrameDecoder：提取固定长度 LengthFieldBasedFrameDecoder：读取头部长度并提取帧的长度 Bootstrap用于引导客户端，以及无连接协议（udp） 下表是 Bootstrap 的常用方法，其中很多是继承自 AbstractBootstrap。 方法 描述 group 设置 EventLoopGroup 用于处理所有的 Channel 的事件 channel channelFactory channel() 指定 Channel 的实现类。如果类没有提供一个默认的构造函数,你可以调用 channelFactory() 来指定一个工厂类被 bind() 调用。 localAddress 指定应该绑定到本地地址 Channel。如果不提供,将由操作系统创建一个随机的。或者,您可以使用 bind() 或 connect()指定localAddress option 设置 ChannelOption 应用于 新创建 Channel 的 ChannelConfig。这些选项将被 bind 或 connect 设置在通道,这取决于哪个被首先调用。这个方法在创建管道后没有影响。所支持 ChannelOption 取决于使用的管道类型。 attr 这些选项将被 bind 或 connect 设置在通道,这取决于哪个被首先调用。这个方法在创建管道后没有影响。 handler 设置添加到 ChannelPipeline 中的 ChannelHandler 接收事件通知。 clone 创建一个当前 Bootstrap的克隆拥有原来相同的设置。 remoteAddress 设置远程地址。此外,您可以通过 connect() 指定 connect 连接到远端，返回一个 ChannelFuture, 用于通知连接操作完成 bind 将通道绑定并返回一个 ChannelFuture,用于通知绑定操作完成后,必须调用 Channel.connect() 来建立连接。 如何引导客户端 Bootstrap 类负责创建管道给客户或应用程序，利用无连接协议和在调用 bind() 或 connect() 之后。下面演示了引导客户端，使用的是 NIO TCP 传输 123456789101112131415161718192021222324252627EventLoopGroup group = new NioEventLoopGroup();Bootstrap bootstrap = new Bootstrap(); //1bootstrap.group(group) //2 .channel(NioSocketChannel.class) //3 .handler(new SimpleChannelInboundHandler&lt;ByteBuf&gt;() &#123; //4 @Override protected void channeRead0( ChannelHandlerContext channelHandlerContext, ByteBuf byteBuf) throws Exception &#123; System.out.println("Received data"); byteBuf.clear(); &#125; &#125;);ChannelFuture future = bootstrap.connect( new InetSocketAddress("www.manning.com", 80)); //5future.addListener(new ChannelFutureListener() &#123; @Override public void operationComplete(ChannelFuture channelFuture) throws Exception &#123; if (channelFuture.isSuccess()) &#123; System.out.println("Connection established"); &#125; else &#123; System.err.println("Connection attempt failed"); channelFuture.cause().printStackTrace(); &#125; &#125; &#125;); ServerBootstrap下表显示了 ServerBootstrap 的方法 方法 描述 group 设置 EventLoopGroup 用于 ServerBootstrap。这个 EventLoopGroup 提供 ServerChannel 的 I/O 并且接收 Channel channelChannelFactory channel() 指定 Channel 的实现类。如果管道没有提供一个默认的构造函数,你可以提供一个 ChannelFactory。 localAddress 指定 ServerChannel 实例化的类。如果不提供,将由操作系统创建一个随机的。或者,您可以使用 bind() 或 connect()指定localAddress option 指定一个 ChannelOption 来用于新创建的 ServerChannel 的 ChannelConfig 。这些选项将被设置在管道的 bind() 或 connect(),这取决于谁首先被调用。在此调用这些方法之后设置或更改 ChannelOption 是无效的。所支持 ChannelOption 取决于使用的管道类型。 childOption 当管道已被接受，指定一个 ChannelOption 应用于 Channel 的 ChannelConfig。 attr 指定 ServerChannel 的属性。这些属性可以被 管道的 bind() 设置。当调用 bind() 之后，修改它们不会生效。 childAttr 应用属性到接收到的管道上。后续调用没有效果。 handler 设置添加到 ServerChannel 的 ChannelPipeline 中的 ChannelHandler。 具体详见 childHandler() 描述 childHandler 设置添加到接收到的 Channel 的 ChannelPipeline 中的 ChannelHandler。handler() 和 childHandler()之间的区别是前者是接收和处理ServerChannel，同时 childHandler() 添加处理器用于处理和接收 Channel。后者代表一个套接字绑定到一个远端。 clone 克隆 ServerBootstrap 用于连接到不同的远端，通过设置相同的原始 ServerBoostrap。 bind 绑定 ServerChannel 并且返回一个 ChannelFuture,用于 通知连接操作完成了（结果可以是成功或者失败） 如何引导一个服务器 ServerBootstrap 中的 childHandler(), childAttr() 和 childOption() 是常用的服务器应用的操作。具体来说,ServerChannel实现负责创建子 Channel,它代表接受连接。因此 引导 ServerChannel 的 ServerBootstrap ,提供这些方法来简化接收的 Channel 对 ChannelConfig 应用设置的任务。 ServerChannel 创建 ServerBootstrap 在 bind(),后者管理大量的子 Channel。 1.当调用 bind() 后 ServerBootstrap 将创建一个新的管道，这个管道将会在绑定成功后接收子管道 2.接收新连接给每个子管道 3.接收连接的 Channel child* 的方法都是操作在子的 Channel，被 ServerChannel 管理。 ServerBootstrap 时会创建一个 NioServerSocketChannel实例 bind() 。这个 NioServerChannel 负责接受新连接和创建NioSocketChannel 实例。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class HttpServer &#123; public static void startServer(int port) &#123;// 创建两个线程组 用于处理网路事件// 一个用来接收客户端的连接// 一个用来进行SocketChannel 的网络读写 @Cleanup(value = "shutdownGracefully") EventLoopGroup bossGroup = new NioEventLoopGroup(); @Cleanup(value = "shutdownGracefully") EventLoopGroup workGroup = new NioEventLoopGroup(); //辅助启动类 ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap .channel(NioServerSocketChannel.class) //注册两个线程组 .group(bossGroup, workGroup) //tcp 属性，不能处理的的请求放入队队列的队列大小 .option(ChannelOption.SO_BACKLOG, 1024) //tcp 属性 长连接 .childOption(ChannelOption.SO_KEEPALIVE, true) .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; @Override protected void initChannel(SocketChannel ch) throws Exception &#123; ch.pipeline().addLast("encoder", new HttpResponseEncoder()); // ChannelInboundHandlerAdapter 必须在 out之后， in 执行顺序为 顺序，out 为倒叙 ch.pipeline().addLast(new HttpOutHandler()); ch.pipeline().addLast(new HttpOutHandler2()); ch.pipeline().addLast("decoder", new HttpRequestDecoder()); //http 请求片段整合得到完整的FullHttpRequest ch.pipeline().addLast("aggregator", new HttpObjectAggregator(10 * 1024 * 1024)); ch.pipeline().addLast(new HttpInHandler()); ch.pipeline().addLast(new HttpInHandler2()); ch.pipeline().addLast(new HttpInHandler3()); &#125; &#125;); try &#123; //阻塞代码直到绑定成功 ChannelFuture future = serverBootstrap.bind(port).sync(); //阻塞代码直到连接关闭 future.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;// public static void main(String[] args) &#123;// startServer(8085);// &#125;&#125; 单元测试1234567@Testpublic void test() &#123; EmbeddedChannel channel = new EmbeddedChannel(new HttpInHandler()); //写一个入站消息 System.out.println(channel.writeInbound(new DefaultFullHttpRequest(HttpVersion.HTTP_1_1, HttpMethod.GET,"/test")));&#125; 方法 描述 writeInbound 写一个入站消息到 EmbeddedChannel。 如果数据能从 EmbeddedChannel 通过 readInbound() 读到，则返回 true readInbound 从 EmbeddedChannel 读到入站消息。任何返回遍历整个ChannelPipeline。如果读取还没有准备，则此方法返回 null writeOutbound 写一个出站消息到 EmbeddedChannel。 如果数据能从 EmbeddedChannel 通过 readOutbound() 读到，则返回 true readOutbound 从 EmbeddedChannel 读到出站消息。任何返回遍历整个ChannelPipeline。如果读取还没有准备，则此方法返回 null Finish 如果从入站或者出站中能读到数据，标记 EmbeddedChannel 完成并且返回。这同时会调用 EmbeddedChannel 的关闭方法]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery-分布式任务队列]]></title>
    <url>%2F2019%2F03%2F28%2FCelery%20-%20%E5%88%86%E5%B8%83%E5%BC%8F%E4%BB%BB%E5%8A%A1%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[Celery 是一个简单、灵活且可靠的，处理大量消息的分布式系统，并且提供维护这样一个系统的必需工具。 它是一个专注于实时处理的任务队列，同时也支持任务调度。 原理在celery 中主要有4个角色，productor ，broker，worker，backend productor 作为生产者发布任务 broker 是消息队列 用于存储任务 官方推荐使用 RabbitMQ 或者redis worker 消费者， 任务处理逻辑 backend 处理结果 如何使用配置12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# -*- coding: utf-8 -*-from kombu import Exchange, Queue# broker 连接，这里使用redisBROKER_URL = "redis://172.16.101.24:6379/1"# BACKEND 连接，这里使用redisCELERY_RESULT_BACKEND = "redis://172.16.101.24:6379/2"# 任务序列化方式CELERY_TASK_SERIALIZER = "json"CELERY_RESULT_SERIALIZER = 'json'CELERY_TASK_RESULT_EXPIRES = 24 * 60 * 60# 如果任务没有在 可见性超时 内确认接收，任务会被重新委派给另一个职程并执行。BROKER_TRANSPORT_OPTIONS = &#123;'visibility_timeout': 43200&#125;# 内存泄漏# 长时间运行Celery有可能发生内存泄露，可以像下面这样设置CELERYD_CONCURRENCY = 20 # 并发worker数CELERYD_MAX_TASKS_PER_CHILD = 40 # 每个worker执行了多少任务就会死掉 防止内存溢出CELERY_QUEUES = ( Queue("default", Exchange("default"), routing_key="default"), Queue("multiplication_task_queue", Exchange("multiplication_task"), routing_key="multiplication_task"), Queue("sum_all", Exchange("sum_all"), routing_key="sum_all"), Queue("add_task_queue", Exchange("add_task"), routing_key="add_task"))# 定义每个任务使用的队列，不同的任务，最好使用不同的队列 以免混乱CELERY_ROUTES = &#123; 'task.multiplication_task': &#123;"queue": "multiplication_task_queue", "routing_key": "multiplication_task"&#125;, 'task.sum_all': &#123;"queue": "sum_all", "routing_key": "sum_all"&#125;, 'task.add_task': &#123;"queue": "add_task_queue", "routing_key": "add_task"&#125;&#125;# celery -A proj worker --loglevel=INFO --concurrency=10 -n worker1.%h -Q for_task# 定时任务配置CELERYBEAT_SCHEDULE = &#123; 'add-every-30-seconds': &#123; 'task': 'tasks.add', 'schedule': timedelta(seconds=30), 'args': (16, 16) &#125;,&#125; worker1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#!/usr/bin/env python# -*- coding: utf-8 -*-from celery import Celery, platforms, Task, chainimport timeplatforms.C_FORCE_ROOT = Trueapp = Celery()# 引入配置app.config_from_object("celeryconfig")class CalculationTask(Task): # 任务成功回调 def on_success(self, retval, task_id, args, kwargs): print 'task done: &#123;0&#125;'.format(retval) return super(CalculationTask, self).on_success(retval, task_id, args, kwargs) # 任务失败回调 def on_failure(self, exc, task_id, args, kwargs, einfo): print 'task fail, reason: &#123;0&#125;'.format(exc) return super(CalculationTask, self).on_failure(exc, task_id, args, kwargs, einfo)# 不关心结果# @app.task(ignore_result=True)# bind=True 时 Task 本身会作为第一个参数 注入到 函数中@app.task(bind=True, max_retries=3, default_retry_delay=1 * 6)def multiplication_task(self, x, y): try: time.sleep(1) # raise Exception("test") return x * y except Exception as exc: # 异常重试 这里countdown 的优先级大于 default_retry_delay self.retry(exc=exc, countdown=10)@app.task(base=CalculationTask)def add_task(x, y): time.sleep(1) return x + y@app.taskdef sum_all(x=None): return sum(x) 进入work 所在的目录 执行命令 celery -A task worker –loglevel=INFO -n worker1.%h worker 就启动起来了（可以启动多个， 注意修改一下名字作区分） 调度任务（product）12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758#!/usr/bin/env python# -*- coding: utf-8 -*-from task import *from celery import group, chordimport timestart = time.time()addresult = [add_task.delay(i, i) for i in range(10)]mult_result = [multiplication_task.delay(i, i) for i in range(20)]for re in addresult: print "加法：", re.get()for re in mult_result: print "乘法：", re.get()print "cost:&#123;&#125;".format(str(time.time() - start))result = add_task.apply_async((2, 2), link=[add_task.s(16), add_task.s(15)])print result.get()print result.children[0].get()# chain# 串行调用# chain 函数接受一个任务的列表，Celery 保证一个 chain 里的子任务会依次执行，# 在 AsynResult 上执行 get 会得到最后一个任务的返回值。和 link 功能类似，# 每一个任务执行结果会当作参数传入下一个任务，所以如果你不需要这种特性，采用 immutable signature (si)来取消。result = chain(add_task.s(1, 2), add_task.s(3), add_task.s(4))()# result = chain(add_task.si(1, 2), add_task.si(3, 3), add_task.si(4, 4))()print result.get()print result.parent.parent.graph# Groups# 并行调用#result = group(add_task.s(1, 2), add_task.s(2, 3), add_task.s(2, 4))()print result.get()# Chords# 先并行调用，再串行调用 4+8+16# 两种写法等价# result=chord((add_task.s(2, 2), add_task.s(4, 4), add_task.s(8, 8)), sum_all.s())()result = chain(group(add_task.s(2, 2), add_task.s(4, 4), add_task.s(8, 8)), sum_all.s())()print result.get()# map# 对并行调用的结果各自汇总result = sum_all.map([range(10), range(100)]).delay()print result.get()# Starmap# 对并行调用的结果各自汇总，汇总参数是tupleresult = add_task.starmap(zip(range(10), range(10))).delay()print result.get()]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>celery</tag>
        <tag>分布式</tag>
        <tag>任务队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程之ThreadPoolExecutor]]></title>
    <url>%2F2019%2F03%2F06%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B9%8BThreadPoolExecutor%2F</url>
    <content type="text"><![CDATA[构造函数1234567public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) 解释一下这几个参数 corePoolSize：线程池核心线程数量；线程池刚刚创建的时候线程池中有0个线程在执行任务，当任务提交到线程池时，如果当前线程数量小于corePoolSize，就会创建新的线程执行任务；如果当前线程已经等于corePoolSize，就会把任务放在workQueue任务队列中。 maximumPoolSize：线程池最大线程数量；当workQueue任务队列已满，此时如果添加新的任务，线程池就会创建新的线程来执行任务，但是最大不会超过maximumPoolSize keepAliveTime：线程池中线程的数量大于corePoolSize时，空闲线程的超时回收时间。如果 allowCoreThreadTimeOut为true 则核心线程也会超时回收。 threadFactory：创建线程的工厂。 handler：拒绝策略，当workQueue已满而且线程数达到maximumPoolSize，无法处理新来的任务时的拒绝策略。 ## addWorker方法1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; //创建工作线程 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); //判断线程是否被SHUTDOWN if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; //开始执行运行线程 t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) addWorkerFailed(w); &#125; return workerStarted;&#125; 在里面完成了状态检查、新建任务、执行任务等一系列动作。可以看到上面创建线程的流程和上面画的图一样。 接下来看t.start();到底做了什么 12345Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125; 在Worker 的构造函数里面可以看到 Worker.thread 是使用自己来构造的一个线程，所以上面的t.start() 所执行的就是work的run方法。也就是runWorker runWorker12345678910111213141516171819202122232425262728293031323334353637383940414243final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125; &#125; 可以看到这个方法一直在执行我们提交的任务的run() 方法，第一次会执行创建这个线程的任务的run方法，后面会执通过getTask()方法重队列里面的任务。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
        <tag>ThreadPool</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[权限管理设计思路]]></title>
    <url>%2F2019%2F02%2F28%2F%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF%2F</url>
    <content type="text"><![CDATA[最近公司的运营管理系统开发完毕，有时间来写点东西，就先来总结一下我再权限系统的设计思路吧，希望能有点用。 权限管理分为 功能权限以及数据权限。 功能权限功能权限是指某个用户使用某个功能的权限 ，简单的说就是调用某个接口的权限。 功能权限比较简单，主要要有三个实体： 用户：保存用户信息 角色：用户的角色信息 权限：权限信息 通过 用户绑定角色，角色绑定权限来实现对用户权限的控制，他们之间都是多对多的关系。 数据权限数据权限就是指不同的用户，使用同样的接口得到数据数量，数据维度不同，所以数据权限又分为行级权限以及列级权限。 数据权限-行级权限行级权限可能会涉及到层级关系，比如销售数据： 普通员工能只能看自己的销售数据 销售组长能看这个组及自己的，部门领导能看所有的。还会有跨部门的权限情况：比如财务部的任何一个人都能看销售部所有的数据。 行级数据权限表设计（主要字段）： 字段1: source_type：需要配置权限的类型（角色或者部门） 字段2: source_id：角色id 或者部门id 字段3: target_type：source 能访问的目标数据的 类型（角色或者部门） 字段3: target_id：角色id或者部门id 这样一条数据的意思是，source角色或者部门下的人员能够访问target角色或者部门下人员的所有数据。 数据权限-列级权限列级数据权限表设计（主要字段）： 字段1: source_type：需要配置权限的类型（角色或者部门） 字段2: source_id：角色id 或者部门id 字段3: target_type：source 能访问的目标数据的 类型（客户列表） 字段3: target_colums：列名 逗号分隔 实现 再用户登陆的时候 将这个用户信息，权限信息，根据以上结构查出来，放到缓存里（redis） 功能权限的实现都在过滤器（filter）里面，有相应的权限才放行。 数据权限就是在各个数据接口中，根据每个用户的配置的数据权限动态生成sql ，select 中的值是列级权限的配置，where 条件中加上 行级权限的相关配置。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>模块设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java多线程基础]]></title>
    <url>%2F2019%2F01%2F15%2Fjava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[等待池假设一个线程a 调用了某个对象的wait方法，线程a就会释放该锁，进入到该对象的等待池中。等待池中的线程不会参与锁的竞争。 锁池假设线程a已经拥有了某个对象的锁，而其他线程想要执行这个对象的某个同步代码块（syschronized）的代码,由于这些线程在进入对象的同步代码块（syschronized）之前必须先获得这个对象的锁，但是该对象的锁目前正被线程a拥有，所以这些线程就进入了该对象的锁池中。 wait wait 方法只能在同步代码块（syschronized）中调用，调用后就会释放该锁，进入到等待池中。（暂时失去锁机制 wait（long timeOut）到超时时间后还需要返还对象锁）； 进入wait 状态的线程能够被notify 和notiffyAll唤醒，然后从等待池进入锁池中参与锁的竞争 wait通常有条件的执行，直到某个条件为真（while） sleepsleep 使当前线程进入停滞状态（阻塞当前线程），让出cpu的使用，目的使不让线程独自霸占该进程的所获的所有cpu资源，留给其他线程执行的机会。 sleep 使Thread的静态方法，他不能改变对象的锁，所以当在一个同步代码块中调用sleep方法，虽然线程休眠了，但是对象的锁并没有被释放，其他线程不能访问这个对象的锁； 在sleep的休眠期满了之后，该线程不一点会立即执行，这是因为其他线程可能正在运行而且没有被调度为放弃执行，除非此线程有更高的优先级。 yieldyield 和sleep大部分一样， yield和sleep的主要区别是，yield会临时暂停当前正在执行的线程，来让有同样优先级的线程有机会执行，或则等待线程的优先级都比较低，那么该线程会继续执行。执行了yeild方法的线程，什么时候会继续运行由调度器来决定。 notifynotify 调用后 只会将等待池中的一个随机移到锁池，所以这个函数使用不当会造成死锁，当这个被移到锁池的线程获得锁之后没有唤醒其他线程（调用notigy，notifyAll）就会可能造成死锁。因为在等待池中的线程不会参与锁的竞争。 notifyAllnotifyAll 会将等待池中的全部线程移到锁池。 原子性Java的原子性就和数据库事务的原子性差不多，一个操作中要么全部执行成功或者失败。 JMM只是保证了基本的原子性，但类似于i++之类的操作，看似是原子操作，其实里面涉及到: 获取 i 的值。 自增。 再赋值给 i。 这三步操作，所以想要实现i++这样的原子操作就需要用到synchronized或者是lock进行加锁处理。 可见性由于CPU直接从主内存中读取数据的效率不高，所以都会对应的CPU高速缓存，先将主内存中的数据读取到缓存中，线程修改数据之后首先更新到缓存，之后才会更新到主内存。如果此时还没有将数据更新到主内存其他的线程此时来读取就是修改之前的数据。 volatile关键字就是用于保证内存可见性，当线程A更新了 volatile 修饰的变量时，它会立即刷新到主线程，并且将其余缓存中该变量的值清空，导致其余线程只能去主内存读取最新值。 使用volatile关键词修饰的变量每次读取都会得到最新的数据，不管哪个线程对这个变量的修改都会立即刷新到主内存。 synchronized和加锁也能能保证可见性，实现原理就是在释放锁之前其余线程是访问不到这个共享变量的。但是和volatile相比开销较大。 顺序性正常情况下的执行顺序应该是1&gt;&gt;2&gt;&gt;3。但是有时JVM为了提高整体的效率会进行指令重排导致执行的顺序可能是2&gt;&gt;1&gt;&gt;3。但是JVM也不能是什么都进行重排，是在保证最终结果和代码顺序执行结果一致的情况下才可能进行重排。 重排在单线程中不会出现问题，但在多线程中会出现数据不一致的问题。 Java 中可以使用volatile来保证顺序性，synchronized 和 lock也可以来保证有序性，和保证原子性的方式一样，通过同一段时间只能一个线程访问来实现的。 除了通过volatile关键字显式的保证顺序之外，JVM还通过happen-before原则来隐式的保证顺序性。 其中有一条就是适用于volatile关键字的，针对于volatile关键字的写操作肯定是在读操作之前，也就是说读取的值肯定是最新的。 123456789101112131415161718public class Singleton &#123; private static volatile Singleton singleton; private Singleton() &#123; &#125; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 这里的volatile关键字主要是为了防止指令重排。 如果不用volatile，singleton = new Singleton();，这段代码其实是分为三步： 分配内存空间。(1) 初始化对象。(2) 将singleton对象指向分配的内存地址。(3) 加上volatile是为了让以上的三步操作顺序执行，反之有可能第三步在第二步之前被执行就有可能导致某个线程拿到的单例对象还没有初始化，以致于使用报错。 volatilevolatile关键字只能保证可见性，顺序性，不能保证原子性。]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android ClassLoader]]></title>
    <url>%2F2019%2F01%2F14%2FAndroid%20ClassLoder%2F</url>
    <content type="text"><![CDATA[一个运行的Android应用至少有2个ClassLoader，一个是BootClassLoader(系统启动时创建的)，一个是PathClassLoader(应用启动时创建的，用于加载/data/data/packagename/apkname.apk) android中应用的类加载器主要有两种，分别是PathClassLoader和DexClassLoader，PathClassLoader只能用来加载已安装应用的dex文件，而DexClassLoader可以用来加载未安装的apk\jar等文件； PathClassLoder12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/** * Provides a simple &#123;@link ClassLoader&#125; implementation that operates on a list * of files and directories in the local file system, but does not attempt to * load classes from the network. Android uses this class for its system class * loader and for its application class loader(s). */public class PathClassLoader extends BaseDexClassLoader &#123; /** * Creates a &#123;@code PathClassLoader&#125; that operates on a given list of files * and directories. This method is equivalent to calling * &#123;@link #PathClassLoader(String, String, ClassLoader)&#125; with a * &#123;@code null&#125; value for the second argument (see description there). * * @param dexPath the list of jar/apk files containing classes and * resources, delimited by &#123;@code File.pathSeparator&#125;, which * defaults to &#123;@code ":"&#125; on Android * @param parent the parent class loader */ public PathClassLoader(String dexPath, ClassLoader parent) &#123; super(dexPath, null, null, parent); &#125; /** * Creates a &#123;@code PathClassLoader&#125; that operates on two given * lists of files and directories. The entries of the first list * should be one of the following: * * &lt;ul&gt; * &lt;li&gt;JAR/ZIP/APK files, possibly containing a "classes.dex" file as * well as arbitrary resources. * &lt;li&gt;Raw ".dex" files (not inside a zip file). * &lt;/ul&gt; * * The entries of the second list should be directories containing * native library files. * * @param dexPath the list of jar/apk files containing classes and * resources, delimited by &#123;@code File.pathSeparator&#125;, which * defaults to &#123;@code ":"&#125; on Android * @param libraryPath the list of directories containing native * libraries, delimited by &#123;@code File.pathSeparator&#125;; may be * &#123;@code null&#125; * @param parent the parent class loader */ public PathClassLoader(String dexPath, String libraryPath, ClassLoader parent) &#123; super(dexPath, null, libraryPath, parent); &#125;&#125; PathClassLoader是ClassLoader的简单实现且只能加载本地的列表文件或目录，在Android中也就是已安装好的APK，它不能加载来自网络的类。Android中的系统类加载器与应用类加载器都是PathClassLoader。 PathClassLoader是ClassLoader的简单实现且只能加载本地的列表文件或目录，在Android中也就是已安装好的APK，它不能加载来自网络的类。Android中的系统类加载器与应用类加载器都是PathClassLoader。 Android系统使用PathClassLoader来加载系统类和应用程序的类，如果是加载非系统应用程序类，则会加载data/app/目录下的dex文件以及包含dex的apk文件或jar文件，不管是加载那种文件，最终都是要加载dex文件，在这里为了方便理解，我们将dex文件以及包含dex的apk文件或jar文件统称为dex相关文件。PathClassLoader不建议开发直接使用。PathClassLoader继承自BaseDexClassLoader，很明显PathClassLoader的方法实现都在BaseDexClassLoader中。从PathClassLoader的构造方法也可以看出它遵循了双亲委托模式。 dexPath：包含dex文件的JAR/ZIP/APK文件的路径 librarySearchPath：native library文件的路径 parent：父类加载器 DexClassLoader123456789101112131415161718192021222324252627282930313233343536373839/** * A class loader that loads classes from &#123;@code .jar&#125; and &#123;@code .apk&#125; files * containing a &#123;@code classes.dex&#125; entry. This can be used to execute code not * installed as part of an application. * * &lt;p&gt;This class loader requires an application-private, writable directory to * cache optimized classes. Use &#123;@code Context.getDir(String, int)&#125; to create * such a directory: &lt;pre&gt; &#123;@code * File dexOutputDir = context.getDir("dex", 0); * &#125;&lt;/pre&gt; * * &lt;p&gt;&lt;strong&gt;Do not cache optimized classes on external storage.&lt;/strong&gt; * External storage does not provide access controls necessary to protect your * application from code injection attacks. */public class DexClassLoader extends BaseDexClassLoader &#123; /** * Creates a &#123;@code DexClassLoader&#125; that finds interpreted and native * code. Interpreted classes are found in a set of DEX files contained * in Jar or APK files. * * &lt;p&gt;The path lists are separated using the character specified by the * &#123;@code path.separator&#125; system property, which defaults to &#123;@code :&#125;. * * @param dexPath the list of jar/apk files containing classes and * resources, delimited by &#123;@code File.pathSeparator&#125;, which * defaults to &#123;@code ":"&#125; on Android * @param optimizedDirectory directory where optimized dex files * should be written; must not be &#123;@code null&#125; * @param libraryPath the list of directories containing native * libraries, delimited by &#123;@code File.pathSeparator&#125;; may be * &#123;@code null&#125; * @param parent the parent class loader */ public DexClassLoader(String dexPath, String optimizedDirectory, String libraryPath, ClassLoader parent) &#123; super(dexPath, new File(optimizedDirectory), libraryPath, parent); &#125;&#125; DexClassLoader可以从包含dex文件的JAR或APK中来加载类，而这些代码源允许不必是安装应用的一部分，因此可用于动态加载。 构造方法中有一个新的参数为optimizedDirectory，它表示优化后的dex文件要写入的路径。通常建议使用如下路径： context.getCodeCacheDir(); 总结 PathClassLoader: 主要用于系统和app的类加载器,其中optimizedDirectory为null, 采用默认目录/data/dalvik-cache/ DexClassLoader: 可以从包含classes.dex的jar或者apk中，加载类的类加载器, 可用于执行动态加载,但必须是app私有可写目录来缓存odex文件. 能够加载系统没有安装的apk或者jar文件， 因此很多插件化方案都是采用DexClassLoader; BaseDexClassLoader: 比较基础的类加载器, PathClassLoader和DexClassLoader都只是在构造函数上对其简单封装而已.]]></content>
      <categories>
        <category>Android逆向</category>
      </categories>
      <tags>
        <tag>Android</tag>
        <tag>ClassLoader</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java classLoader]]></title>
    <url>%2F2019%2F01%2F04%2Fjava%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8%2F</url>
    <content type="text"><![CDATA[在 Java 中，类的实例化流程分为两个部分：类的加载和类的实例化。类的加载又分为显式加载和隐式加载。大家使用 new 关键字创建类实例时，其实就隐式地包含了类的加载过程。对于类的显式加载来说，比较常用的是 Class.forName。其实，它们都是通过调用 ClassLoader 类的 loadClass 方法来完成类的实际加载工作的。 java类加载层次解构ClassLoader 在加载类时有一定的层次关系和规则。在 Java 中，有四种类型的类加载器，从上到下分别为：BootStrapClassLoader、ExtClassLoader、AppClassLoader 以及用户自定义的 ClassLoader。这四种类加载器分别负责不同路径的类的加载，并形成了一个类加载的层次结构。 bootStrapClassLoaderBootstrap ClassLoader最顶层的加载类，主要加载核心类库，%JRE_HOME%\lib下的rt.jar、resources.jar、charsets.jar和class等。可以通过 System.getProperty(“sun.boot.class.path”)获得相应路径。 可以通过启动jvm时指定-Xbootclasspath和路径来改变Bootstrap ClassLoader的加载目录。比如java -Xbootclasspath/a:path被指定的文件追加到默认的bootstrap路径中。 ExtClassLoader扩展的类加载器，加载目录%JRE_HOME%\lib\ext目录下的jar包和class文件。还可以加载-D java.ext.dirs选项指定的目录。可以通过System.out.println(System.getProperty(“java.ext.dirs”));相应路径 AppClassLoaderAppclass Loader也称为SystemAppClass加载当前应用的classpath的所有类。 通过System.out.println(System.getProperty(“java.class.path”));获得相应路径 双亲委托 一个类加载器加载class时，是通过“委托模式”进行的，它首先判断这个class是不是已经加载成功，如果没有的话它并不是自己进行查找，而是先通过父加载器，然后递归下去，直到Bootstrap ClassLoader，如果Bootstrap classloader找到了，直接返回，如果没有找到，则一级一级返回，最后到达自身去查找这些对象。这种机制就叫做双亲委托。 重要方法findLoadedClass每个类加载器都维护有自己的一份已加载类名字空间，其中不能出现两个同名的类。凡是通过该类加载器加载的类，无论是直接的还是间接的，都保存在自己的名字空间中，该方法就是在该名字空间中寻找指定的类是否已存在，如果存在就返回给类的引用，否则就返回 null。这里的直接是指，存在于该类加载器的加载路径上并由该加载器完成加载，间接是指，由该类加载器把类的加载工作委托给其他类加载器完成类的实际加载。 getSystemClassLoader该方法返回系统使用的 ClassLoader。可以在自己定制的类加载器中通过该方法把一部分工作转交给系统类加载器去处理。 defineClass该方法是 ClassLoader 中非常重要的一个方法，它接收以字节数组表示的类字节码，并把它转换成 Class 实例，该方法转换一个类的同时，会先要求装载该类的父类以及实现的接口类。 findClass从指定的路径中查找.class文件，并加载类 loadClass加载类的入口方法，调用该方法完成类的显式加载。通过对该方法的重新实现，我们可以完全控制和管理类的加载过程。]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot及bean 初始化运行]]></title>
    <url>%2F2018%2F12%2F18%2Fspringboot%E5%8F%8Abean%20%E5%88%9D%E5%A7%8B%E5%8C%96%E8%BF%90%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[spring boot 启动时运行Spring Boot应用程序在启动后，会遍历CommandLineRunner接口的实例并运行它们的run方法。也可以利用@Order注解（或者实现Order接口）来规定所有CommandLineRunner实例的运行顺序。 12345678910111213@Order(10)@Componentpublic class ContractUsegeStatusInitRunner implements CommandLineRunner &#123; private static Logger logger= LoggerFactory.getLogger(ContractUsegeStatusInitRunner.class); @Autowired private ScheduleService scheduleService; @Override public void run(String... strings) throws Exception &#123; logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;启动时合同使用状态更新"); scheduleService.updateContractUsegeStatus(); logger.info("&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;合同使用状态更新结束"); &#125; Bean 初始化完成时运行执行顺序 Constructor &gt; @PostConstruct &gt; InitializingBean &gt; init-method &lt;beanclass=”InitSequenceBean”init-method=”initMethod”&gt; 123456789101112131415161718192021public class InitSequenceBean implements InitializingBean &#123; public InitSequenceBean() &#123; System.out.println("InitSequenceBean: constructor"); &#125; @PostConstruct public void postConstruct() &#123; System.out.println("InitSequenceBean: postConstruct"); &#125; public void initMethod() &#123; System.out.println("InitSequenceBean: init-method"); &#125; @Override public void afterPropertiesSet() throws Exception &#123; System.out.println("InitSequenceBean: afterPropertiesSet"); &#125;&#125; Bean销毁之前执行使用@PreDestroy]]></content>
      <tags>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot多个数据库配置]]></title>
    <url>%2F2018%2F11%2F29%2Fspringboot%E5%A4%9A%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[多个redis数据库多个redis配置的基类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137package com.jianganwei.config;import com.fasterxml.jackson.annotation.JsonAutoDetect;import com.fasterxml.jackson.annotation.PropertyAccessor;import com.fasterxml.jackson.databind.ObjectMapper;import org.springframework.beans.factory.annotation.Value;import org.springframework.cache.CacheManager;import org.springframework.cache.annotation.EnableCaching;import org.springframework.cache.interceptor.KeyGenerator;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.connection.jedis.JedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.StringRedisSerializer;import redis.clients.jedis.JedisPoolConfig;import java.lang.reflect.Method;/** * spring-boot-data-packing 设置Redis多实例的基类 * * @Author jianganwei * @Date 2018/8/13 */@EnableCaching@Configurationpublic class RedisConfig &#123; @Value("$&#123;spring.redis.pool.max-active&#125;") private int redisPoolMaxActive; @Value("$&#123;spring.redis.pool.max-wait&#125;") private int redisPoolMaxWait; @Value("$&#123;spring.redis.pool.max-idle&#125;") private int redisPoolMaxIdle; @Value("$&#123;spring.redis.pool.min-idle&#125;") private int redisPoolMinIdle; /** * 配置Key的生成方式 * * @return */ @Bean public KeyGenerator keyGenerator() &#123; return new KeyGenerator() &#123; @Override public Object generate(Object o, Method method, Object... objects) &#123; StringBuilder stringBuilder = new StringBuilder(); stringBuilder.append(o.getClass().getName()) .append(method.getName()); for (Object object : objects) &#123; stringBuilder.append(object.toString()); &#125; return stringBuilder.toString(); &#125; &#125;; &#125; /** * 创建redis连接工厂 * * @param dbIndex * @param host * @param port * @param password * @param timeout * @return */ public JedisConnectionFactory createJedisConnectionFactory(int dbIndex, String host, int port, String password, int timeout) &#123; JedisConnectionFactory jedisConnectionFactory = new JedisConnectionFactory(); jedisConnectionFactory.setDatabase(dbIndex); jedisConnectionFactory.setHostName(host); jedisConnectionFactory.setPort(port); jedisConnectionFactory.setPassword(password); jedisConnectionFactory.setTimeout(timeout); jedisConnectionFactory.setPoolConfig(setPoolConfig(redisPoolMaxIdle, redisPoolMinIdle, redisPoolMaxActive, redisPoolMaxWait, true)); return jedisConnectionFactory; &#125; /** * 设置连接池属性 * * @param maxIdle * @param minIdle * @param maxActive * @param maxWait * @param testOnBorrow * @return */ public JedisPoolConfig setPoolConfig(int maxIdle, int minIdle, int maxActive, int maxWait, boolean testOnBorrow) &#123; JedisPoolConfig poolConfig = new JedisPoolConfig(); poolConfig.setMaxIdle(maxIdle); poolConfig.setMinIdle(minIdle); poolConfig.setMaxTotal(maxActive); poolConfig.setMaxWaitMillis(maxWait); poolConfig.setTestOnBorrow(testOnBorrow); return poolConfig; &#125; /** * 设置RedisTemplate的序列化方式 * * @param redisTemplate */ public void setSerializer(RedisTemplate&lt;Object,Object&gt; redisTemplate) &#123; Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.setHashKeySerializer(jackson2JsonRedisSerializer); redisTemplate.setKeySerializer(new StringRedisSerializer()); redisTemplate.afterPropertiesSet(); &#125; /** * 设置RedisTemplate的序列化方式 * * @param redisTemplate */ public void setSerializerNomal(RedisTemplate redisTemplate) &#123; Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); //设置键（key）的序列化方式 redisTemplate.setKeySerializer(new StringRedisSerializer()); //设置值（value）的序列化方式 redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); &#125;&#125; redis数据库配置redis数据库的配置，第二个第三个类似 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package com.jianganwei.config;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.core.StringRedisTemplate;/** * @program: Bemoan * @description: * @author: jianganwei * @create: 2018-11-28 17:19 **/@Configurationpublic class BemoanRedisConfig extends RedisConfig &#123; @Value("$&#123;spring.redis.bemoan.database&#125;") private int dbIndex; @Value("$&#123;spring.redis.bemoan.host&#125;") private String host; @Value("$&#123;spring.redis.bemoan.port&#125;") private int port; @Value("$&#123;spring.redis.bemoan.timeout&#125;") private String password; @Value("$&#123;spring.redis.bemoan.timeout&#125;") private int timeout; /** * 配置redis连接工厂 * * @return */ @Primary @Bean public RedisConnectionFactory cacheRedisConnectionFactory() &#123; return createJedisConnectionFactory(dbIndex, host, port, password, timeout); &#125; /** * 配置redisTemplate 注入方式使用@Resource(name="") 方式注入 * * @return */ @Bean(name = "bemoanRedis") public RedisTemplate&lt;Object,Object&gt; bemoanRedis() &#123; RedisTemplate&lt;Object,Object&gt; template = new RedisTemplate&lt;Object,Object&gt;(); template.setConnectionFactory(cacheRedisConnectionFactory()); setSerializer(template); template.afterPropertiesSet(); return template; &#125; /** * 配置redisTemplate 注入方式使用@Resource(name="") 方式注入 * * @return */ @Bean(name = "bemoanStringRedis") public StringRedisTemplate stringRedisTemplate() &#123; StringRedisTemplate template = new StringRedisTemplate(); template.setConnectionFactory(cacheRedisConnectionFactory()); setSerializerNomal(template); template.afterPropertiesSet(); return template; &#125;&#125; 多个mysql数据库配置配置类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.jianganwei.config;import org.apache.ibatis.session.SqlSessionFactory;import org.mybatis.spring.SqlSessionFactoryBean;import org.mybatis.spring.SqlSessionTemplate;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.boot.autoconfigure.jdbc.DataSourceBuilder;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.jdbc.datasource.DataSourceTransactionManager;import tk.mybatis.spring.annotation.MapperScan;import javax.sql.DataSource;/** * @program: Bemoan * @description: 个人数据库配置 * @author: jianganwei * @create: 2018-11-29 09:43 **/@Configuration@MapperScan(basePackages = "com.jianganwei.mapper.person",sqlSessionFactoryRef = "personSqlSessionFactory")public class PersonDataSourceConfig &#123; @Bean("personDataSource") @ConfigurationProperties(prefix = "spring.datasource.person") public DataSource personDataSource()&#123; return DataSourceBuilder.create().build(); &#125; @Bean("personSqlSessionFactory") public SqlSessionFactory personSqlSessionFactory(@Qualifier("personDataSource") DataSource dataSource) throws Exception&#123; SqlSessionFactoryBean factoryBean=new SqlSessionFactoryBean(); org.apache.ibatis.session.Configuration configuration=new org.apache.ibatis.session.Configuration(); configuration.setUseGeneratedKeys(true); factoryBean.setDataSource(dataSource); PathMatchingResourcePatternResolver resolver = new PathMatchingResourcePatternResolver(); factoryBean.setMapperLocations(resolver.getResources("classpath:/xml/*.xml")); configuration.setMapUnderscoreToCamelCase(true); factoryBean.setFailFast(true); return factoryBean.getObject(); &#125; @Bean("personTransactionManager") public DataSourceTransactionManager personTransactionManager(@Qualifier("personDataSource") DataSource dataSource)&#123; DataSourceTransactionManager manager=new DataSourceTransactionManager(); manager.setDataSource(dataSource); return manager; &#125; @Bean public SqlSessionTemplate personSqlTemplate(@Qualifier("personDataSource") DataSource dataSource)throws Exception&#123; return new SqlSessionTemplate(personSqlSessionFactory(dataSource)); &#125;&#125; 配置文件12345678910111213141516spring.datasource.person.driver-class-name: com.mysql.jdbc.Driverspring.datasource.person.url: jdbc:mysql://.mysql.rds.aliyuncs.com/jianganwei_spring.datasource.person.username: jianganweispring.datasource.person.password: J_anwei_2017spring.datasource.person.type: com.alibaba.druid.pool.DruidDataSourcespring.datasource.person.initialSize: 5spring.datasource.person.minIdle: 5spring.datasource.person.maxIdle: 100spring.datasource.person.maxActive: 200spring.datasource.person.maxWait: 5000spring.datasource.person.testOnBorrow: falsespring.datasource.person.validationQuery: SELECT 1spring.datasource.person.testWhileIdle: truespring.datasource.person.timeBetweenEvictionRunsMillis: 30000spring.datasource.person.minEvictableIdleTimeMillis: 1800000spring.datasource.person.numTestsPerEvictionRun: 100]]></content>
      <tags>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java jni demo]]></title>
    <url>%2F2018%2F11%2F28%2Fjava%20jni%20demo%2F</url>
    <content type="text"><![CDATA[简介JNI是Java Native Interface的英文缩写, 中文翻译为本地调用, 自从Java 1.1开始就成为了Java标准的一部分. C/C++是系统级的编程语言, 可以用来开发任何和系统相关的程序和类库, 但是Java本身编写底层的应用比较难实现, 使用JNI可以调用现有的本地库, 极大地灵活了Java的开发. C/C++的效率是目前最好的语言, 可以使用C/C++来实现一些实时性非常高的部分. C/C++和Java本身都是非常流行的编程语言, 一些大型软件中经常使用语言之间的混合编程 新建一个HelloJNI类123456789101112131415161718192021package com.jianganwei.demo;/** * @program: Bemoan * @description: JNI * @author: jianganwei * @create: 2018-11-26 14:46 **/public class HelloJNI &#123; static&#123; System.out.println(System.getProperty("java.library.path")); System.loadLibrary("HelloJNI"); &#125; private native void sayHello(); public static void main(String[] args) &#123; new HelloJNI().sayHello(); &#125;&#125; 代码的静态代码块在这个类被类加载器加载的时候调用了System.loadLibrary()方法来加载一个native库“HelloJNI”（这个库中实现了sayHello函数）。这个库在windows品台上对应了“helloJNI.dll”，而在类UNIX平台上对应了“libhelloJNI.so”。这个库应该包含在Java的库路径（使用java.library.path系统变量表示）上，否则这个上面的程序会抛出UnsatisfiedLinkError错误。你应该使用VM的参数-Djava.library.path=path_to_lib来指定包含native库的路径。接下来，我们使用native关键字将sayHello()方法声明为本地实例方法，这就很明显地告诉JVM：这个方法实现在另外一个语言中（C/C++），请去那里寻找他的实现。注意，一个native方法不包含方法体，只有声明。上面代码中的main方法实例化了一个HelloJJNI类的实例，然后调用了本地方法sayHello()。 编译得到.class文件javac HelloJNI.java 获得build一下项目.class 文件 就在target/classes中 链接生成头文件1javah -classpath target/classes -d ./jni com.jianganwei.demo.HelloJNI 会在./jni 这个目录下生成 jni/com_jianganwei_demo_HelloJNI.h 文件内容如下 1234567891011121314151617181920#include &lt;jni.h&gt;/* Header for class com_jianganwei_demo_HelloJNI */#ifndef _Included_com_jianganwei_demo_HelloJNI#define _Included_com_jianganwei_demo_HelloJNI#ifdef __cplusplusextern "C" &#123;#endif/* * Class: com_jianganwei_demo_HelloJNI * Method: sayHello * Signature: ()V */JNIEXPORT void JNICALL Java_com_jianganwei_demo_HelloJNI_sayHello (JNIEnv *, jobject);#ifdef __cplusplus&#125;#endif#endif 在idea中配置一键生成头文件 编写c或c++代码c为.c c++为cpp文件新建文件.c或.cpp文件，实现上一步头文件的接口 12345678#include&lt;jni.h&gt;#include &lt;stdio.h&gt;#include "com_jianganwei_demo_HelloJNI.h"JNIEXPORT void JNICALL Java_com_jianganwei_demo_HelloJNI_sayHello(JNIEnv *env, jobject thisObj)&#123;printf("hello world!\n");return;&#125; 生成.o12gcc -fPIC -c -I"/opt/jdk1.8/jdk1.8.0_151/include" -I"/opt/jdk1.8/jdk1.8.0_151/include/linux" jni/HelloJNI.c 上面是jdk的路径，window 下第2个路径有点不同进去jdk 目录看一下就好了 生成.so文件，win 为dll1gcc -shared HelloJNI.o -o libHello.so 最后把生成的so文件放到java.library.path把so 文件放到某个目录下，或者配置运行时环境 -Djava.library.path=/home/jianganwei/IdeaProjects/Bemoan/lib 到so文件所在目录 最后生成o 和so 文件可以合成一步 1gcc -fPIC -I"/opt/jdk1.8/jdk1.8.0_151/include" -I"/opt/jdk1.8/jdk1.8.0_151/include/linux" -shared -o ./lib/libHelloJNI.so jni/HelloJNI.c idea 配置一键生成]]></content>
      <categories>
        <category>后台</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件处理]]></title>
    <url>%2F2018%2F11%2F28%2F%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C%E9%97%AE%E9%A2%98%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[记录一下在文件处理里面遇到的问题 读excel大文件依赖添加 git地址 12345&lt;dependency&gt; &lt;groupId&gt;com.monitorjbl&lt;/groupId&gt; &lt;artifactId&gt;xlsx-streamer&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt; &lt;/dependency&gt; 示例代码 1234567Workbook workbook = StreamingReader.builder().rowCacheSize(1).bufferSize(4096).open(in); Sheet sheet = workbook.getSheetAt(0); Row firstRow = sheet.rowIterator().next(); Iterator&lt;Cell&gt; iterator = firstRow.cellIterator(); while (iterator.hasNext()) &#123; cellList.add(iterator.next().getStringCellValue()); &#125; 对输入流进行压缩123456789101112131415161718192021222324252627 private InputStream getZipInputStream(InputStream inputStream, String fileName) &#123; byte[] buf = new byte[1024]; try &#123; //ZipOutputStream类：完成文件或文件夹的压缩// ZipOutputStream out = new ZipOutputStream(new FileOutputStream("/home/jianganwei/下载/demo_LOCAL.zip")); ByteArrayOutputStream byteArrayOutputStream=new ByteArrayOutputStream(); ZipOutputStream out = new ZipOutputStream(byteArrayOutputStream); int len; ZipEntry zipEntry = new ZipEntry(fileName);// zipEntry.setUnixMode(666); out.putNextEntry(zipEntry); while ((len = inputStream.read(buf)) &gt; 0) &#123; out.write(buf, 0, len); &#125; out.closeEntry(); inputStream.close(); out.close(); logger.info("压缩完成."+fileName); return new ByteArrayInputStream(byteArrayOutputStream.toByteArray()); &#125; catch (Exception e) &#123;// TODO Auto-generated catch block e.printStackTrace(); return null; &#125; &#125; 123456&lt;!-- https://mvnrepository.com/artifact/org.apache.ant/ant --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ant&lt;/groupId&gt; &lt;artifactId&gt;ant&lt;/artifactId&gt; &lt;version&gt;1.9.3&lt;/version&gt; &lt;/dependency&gt;]]></content>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot整合activiti]]></title>
    <url>%2F2018%2F11%2F08%2Fspringboot%E6%95%B4%E5%90%88activiti%2F</url>
    <content type="text"><![CDATA[添加依赖12345&lt;dependency&gt; &lt;groupId&gt;org.activiti&lt;/groupId&gt; &lt;artifactId&gt;activiti-spring-boot-starter-basic&lt;/artifactId&gt; &lt;version&gt;5.22.0&lt;/version&gt; &lt;/dependency&gt; 配置123456789101112131415161718192021222324252627282930313233343536373839404142434445@Configurationpublic class ActivitiConfig &#123; @Bean(&quot;activityConfig&quot;) public SpringProcessEngineConfiguration getSpringProcessEngineConfiguration( @Qualifier(&quot;reconciliationdb&quot;) DataSource reconciliationdb, @Qualifier(&quot;reconciliationdbTransactionManager&quot;)DataSourceTransactionManager transactionManager)&#123; SpringProcessEngineConfiguration configuration = new SpringProcessEngineConfiguration(); configuration.setDataSource(reconciliationdb); configuration.setTransactionManager(transactionManager); configuration.setActivityFontName(&quot;宋体&quot;); configuration.setLabelFontName(&quot;宋体&quot;);// configuration.setDatabaseSchemaUpdate(ProcessEngineConfigurationImpl.DB_SCHEMA_UPDATE_CREATE) return configuration; &#125; @Bean(&quot;activityProcessEngine&quot;) public ProcessEngine getProcessEngineFactoryBean(@Qualifier(&quot;activityConfig&quot;) SpringProcessEngineConfiguration configuration) throws Exception &#123; ProcessEngineFactoryBean factoryBean = new ProcessEngineFactoryBean(); factoryBean.setProcessEngineConfiguration(configuration); return factoryBean.getObject(); &#125; @Bean public RuntimeService getRuntimeService(@Qualifier(&quot;activityProcessEngine&quot;) ProcessEngine engine) &#123; return engine.getRuntimeService(); &#125; @Bean public RepositoryService getRepositoryService(@Qualifier(&quot;activityProcessEngine&quot;) ProcessEngine engine) &#123; return engine.getRepositoryService(); &#125; @Bean public TaskService getTaskService(@Qualifier(&quot;activityProcessEngine&quot;) ProcessEngine engine) &#123; return engine.getTaskService(); &#125; @Bean public HistoryService getHistoryService (@Qualifier(&quot;activityProcessEngine&quot;) ProcessEngine engine) &#123; return engine.getHistoryService(); &#125;&#125; 官方文档]]></content>
      <tags>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫学习笔记]]></title>
    <url>%2F2018%2F10%2F24%2F%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[数据定位方法 源码文本搜索 chrome search工具 代理服务器拦截 使用dom断点 Js注入拦截 chrome 堆栈信息 chrome console 很强大]]></content>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[springboot自动配置demo]]></title>
    <url>%2F2018%2F10%2F23%2FSpringboot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AEdemo%2F</url>
    <content type="text"><![CDATA[先创建需要自动配置的类123456789101112package com.jianganwei.autoconfigdemo.demo;import org.springframework.beans.factory.annotation.Value;public class AutoconfigDemo &#123; @Value(&quot;$&#123;init.message&#125;&quot;) private String message; public void sout() &#123; System.out.println(&quot;the message is: &quot; + message); &#125;&#125; 编写创建该类的条件12345678910111213141516import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configurationpublic class Demo &#123; @Bean @ConditionalOnMissingBean(AutoconfigDemo.class) @ConfigurationProperties(prefix = &quot;init&quot;) @ConditionalOnProperty(prefix = &quot;init&quot;,value = &quot;message&quot;) public AutoconfigDemo getDemo()&#123; return new AutoconfigDemo(); &#125;&#125; 最后在resources 目录下创建 META-INF/spring.factories在文件中配入需要自动创建的bean 条件类 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.jianganwei.autoconfigdemo.demo.Demo]]></content>
      <tags>
        <tag>Springboot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql学习笔记]]></title>
    <url>%2F2018%2F10%2F10%2Fmysql%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[btree索引与hash索引的区别hash索引的优点hash索引解构的特殊性，其检索效率非常高，btree索引需要充根节点访问到分支节点，这样会有多次的io访问，所以hash索引 的查询效率远高于btree btree索引的优点1.hash索引不能满足范围查询而btree可以这是由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于 等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算 前完全一样。 2.Hash 索引无法被用来避免数据的排序操作。由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的 大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算； 3.Hash 索引不能利用部分索引键查询。对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。 4.Hash 索引在任何时候都不能避免表扫描。Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对 应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录 条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。 注意事项{:.warning} 左连接求和时右边的表相关的列求和可能会重复。 mysql四种事物隔离级别read uncommitted 读未提交，即便是事务没有被提交（commit），但是其他事务能读到未提交的数据，这是隔离级别最低的一种。 read committed读已提交，当前事务只能读到其他事物提交之后的数据，未提交的数据读不到，这个可能造成在同一个事务里，前后读到的数据可能不一样（不可重复读）。大多数数据库默认的隔离级别（oracle） repeatable read可重复读，在事务里，每次读取数据的结果都一样，不管其他事务的结果有没有提交。可能会造成幻读。MySQL默认的隔离级别 serializable串行化，一个事务提交前，其他事物将被挂起。就是说，在同一时间只有一个事务操作表。]]></content>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[quartz定时任务SpringBoot配置]]></title>
    <url>%2F2018%2F09%2F26%2Fquartz%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1SpringBoot%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Quartz是Java领域最著名的开源任务调度工具。Quartz提供了极为广泛的特性如持久化任务，集群和分布式任务官方文档 http://www.quartz-scheduler.org/documentation/quartz-2.1.x/quick-start.html 添加maven依赖1234567891011121314151617181920&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.quartz-scheduler&lt;/groupId&gt; &lt;artifactId&gt;quartz-jobs&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;4.3.13.RELEASE&lt;/version&gt;&lt;/dependency&gt; 解决Job 中bean 无法注入的问题1.建一个JobFactory然后 把其设置为 SchedulerFactoryBean 的 JobFactory。其目的是因为我在具体的Job 中 需要Spring 注入一些Service。所以我们要自定义一个jobfactory， 让其在具体job 类实例化时 使用Spring 的API 来进行依赖注入。 123456789101112131415161718192021import org.quartz.spi.TriggerFiredBundle;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.config.AutowireCapableBeanFactory;import org.springframework.context.annotation.Configuration;import org.springframework.scheduling.quartz.AdaptableJobFactory;import org.springframework.stereotype.Component;@Configuration@Componentpublic class JobFactory extends AdaptableJobFactory &#123; @Autowired private AutowireCapableBeanFactory capableBeanFactory; @Override protected Object createJobInstance(TriggerFiredBundle bundle) throws Exception &#123; //调用父类的方法 Object jobInstance = super.createJobInstance(bundle); //进行注入 capableBeanFactory.autowireBean(jobInstance); return jobInstance; &#125;&#125; 2.新建一个配置类把 SchedulerFactoryBean 设置为自定义的 JobFactory 并用它产生 Scheduler 12345678910111213@Autowiredprivate JobFactory jobFactory;@Bean(name="schedulerFactoryBean")public SchedulerFactoryBean getSchedulerFactoryBean() &#123; SchedulerFactoryBean factoryBean = new SchedulerFactoryBean(); factoryBean.setJobFactory(jobFactory); //factoryBean.setDataSource(datasource); return factoryBean;&#125;@Beanpublic Scheduler scheduler()&#123; return getSchedulerFactoryBean().getScheduler(); Quartz管理器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260package com.jianganwei.sfss.manager.impl;import com.jianganwei.sfss.exception.BusinessException;import org.apache.commons.lang3.StringUtils;import org.quartz.*;import org.quartz.impl.matchers.GroupMatcher;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.time.LocalDateTime;import java.util.*;/** * * Quartz管理器 * @author 李晋科(Jinke Li) * @version QuartzManager.java, 2018年6月12日 上午00:59:49 李晋科(Jinke Li) */@Componentpublic class QuartzManager &#123; private final static Logger LOGGER = LoggerFactory.getLogger(QuartzManager.class); private static Scheduler scheduler; private final static String JOB_GROUP_NAME = "OMS_JOBGROUP_NAME"; private final static String TRIGGER_GROUP_NAME = "OMS_TRIGGERGROUP_NAME"; private final static String TRIGGER_REDO_GROUP_NAME = "OMS_TRIGGERREDOGROUP_NAME"; /** * * job添加 * @param jobName * @param objJobClass * @param time */ public static void addJob(String jobName, Class&lt;? extends Job&gt; objJobClass, String time, Date startTime) &#123; addJob(jobName,objJobClass,time,startTime,null); &#125; /** * * job添加 * @param jobName * @param objJobClass * @param startTime * @param datas * @return */ public static Date addJob(String jobName, Class&lt;? extends Job&gt; objJobClass, String cronExp, Date startTime, Map&lt;String, Object&gt; datas) &#123; Date runTime = null; try &#123; JobDetail jobDetail = JobBuilder.newJob(objJobClass).withIdentity(jobName, JOB_GROUP_NAME).build(); if(datas != null) &#123; jobDetail.getJobDataMap().putAll(datas); &#125; TriggerBuilder&lt;Trigger&gt; builder = TriggerBuilder.newTrigger() .withIdentity(jobName, TRIGGER_GROUP_NAME); if (startTime.getTime() &gt; System.currentTimeMillis()) &#123; builder.startAt(startTime); &#125; if (StringUtils.isNotBlank(cronExp)) &#123; builder.withSchedule(CronScheduleBuilder.cronSchedule(cronExp)); &#125; if (StringUtils.isBlank(cronExp)) &#123; builder.withSchedule(SimpleScheduleBuilder.simpleSchedule()); &#125; Trigger trigger = builder.build(); runTime = scheduler.scheduleJob(jobDetail, trigger); if (scheduler.isShutdown())&#123; scheduler.start(); &#125; &#125; catch (Exception e) &#123; LOGGER.error("添加job出错",e); &#125; return runTime; &#125; /** * * job重试调度 * @param jobName * @param objJobClass * @param startTime * @param interval * @param repeatTimes * @param datas * @return */ public static Date addRedoJob(String jobName, Class&lt;? extends Job&gt; objJobClass, Date startTime, int interval, int repeatTimes, Map&lt;String, Object&gt; datas)&#123; Date runTime = null; JobDetail jobDetail = null; try &#123; JobKey jobKey = new JobKey(jobName, JOB_GROUP_NAME); if(scheduler.checkExists(jobKey)) &#123; jobDetail = scheduler.getJobDetail(jobKey); &#125; if(jobDetail == null) &#123; jobDetail = JobBuilder.newJob(objJobClass).withIdentity(jobKey).build(); if(datas != null) &#123; jobDetail.getJobDataMap().putAll(datas); &#125; &#125; SimpleTrigger trigger = TriggerBuilder.newTrigger() .withIdentity(jobName+"_redo_"+LocalDateTime.now(), TRIGGER_REDO_GROUP_NAME) .forJob(jobDetail) .withSchedule(SimpleScheduleBuilder.simpleSchedule().withIntervalInMinutes(interval).withRepeatCount(repeatTimes)) .startAt(startTime) .build(); runTime = scheduler.scheduleJob(trigger); &#125; catch (SchedulerException e) &#123; LOGGER.error("job重试调度出错",e);// throw new PcreditTaskEngineException("job重试调度出错",e); &#125; return runTime; &#125; /** * 移除所有重试任务 * 有重试任务移除返回true 无返回false * @param jobKey */ public static boolean unScheduleRedo(JobKey jobKey) &#123; try &#123; List&lt;? extends Trigger&gt; list = scheduler.getTriggersOfJob(jobKey); if (null != list) &#123; for(Trigger trigger: list) &#123; if(TRIGGER_REDO_GROUP_NAME.equals(trigger.getKey().getGroup())) &#123; scheduler.unscheduleJob(trigger.getKey()); return true; &#125; &#125; &#125; &#125; catch (SchedulerException e) &#123; LOGGER.error("取消重任务失败 jobName&#123;&#125;",jobKey,e); &#125; return false; &#125; /** * 取消任务计划(仅) * @param triggerKey */ public static void unScheduleJob(TriggerKey triggerKey) &#123; try &#123; scheduler.unscheduleJob(triggerKey); &#125; catch (SchedulerException e) &#123; LOGGER.error("取消任务失败 triggerName&#123;&#125;",triggerKey.getName(),e); &#125; &#125; /** * * job移除 * @param jobName */ public static void removeJob(String jobName) &#123; try &#123; scheduler.pauseTrigger(new TriggerKey(jobName, TRIGGER_GROUP_NAME)); scheduler.unscheduleJob(new TriggerKey(jobName, TRIGGER_GROUP_NAME)); scheduler.deleteJob(new JobKey(jobName, JOB_GROUP_NAME)); &#125; catch (Exception e) &#123; LOGGER.error("移除job抛错",e); &#125; &#125; /** * 删除所有任务 */ public static void removeAllJob() &#123; try &#123; GroupMatcher&lt;JobKey&gt; matcher = GroupMatcher.groupEquals(JOB_GROUP_NAME); Set&lt;JobKey&gt; jobkeySet = null; jobkeySet = scheduler.getJobKeys(matcher); List&lt;JobKey&gt; jobkeyList = new ArrayList&lt;JobKey&gt;(); jobkeyList.addAll(jobkeySet); scheduler.deleteJobs(jobkeyList); &#125; catch (SchedulerException e) &#123; e.printStackTrace(); &#125; &#125; /** * 检查任务存在 * * @param jobName * @return */ public static boolean checkJobExists(String jobName)&#123; try &#123; JobKey jobKey = new JobKey(jobName, JOB_GROUP_NAME); return scheduler.checkExists(jobKey); &#125; catch (Exception e) &#123; LOGGER.error("检查任务出错",e); throw new BusinessException("100000000","检查任务出错",1); &#125; &#125; /** * 开启调度 */ public static void startJobs() &#123; try &#123; scheduler.start(); &#125; catch (Exception e) &#123; LOGGER.error("启动调度出错",e); &#125; &#125; /** * 关闭调度-关闭后不能重启 */ public static void shutdownJobs() &#123; try &#123; if(!scheduler.isShutdown()) &#123; scheduler.shutdown(); &#125; &#125; catch (Exception e) &#123; LOGGER.error("关闭调度出错",e); &#125; &#125; /** * Getter method for &lt;tt&gt;scheduler&lt;/tt&gt;. * * @return value of scheduler */ public static Scheduler getScheduler() &#123; return scheduler; &#125; /** * Setter method for &lt;tt&gt;scheduler&lt;/tt&gt;. * * @param scheduler value to be assigned to scheduler */ public static void setScheduler(Scheduler scheduler) &#123; QuartzManager.scheduler = scheduler; &#125;&#125; 初始化123456789101112131415161718192021222324252627282930313233package com.jianganwei.sfss.init;import com.jianganwei.sfss.manager.impl.QuartzManager;import com.jianganwei.sfss.schedule.AlarmTaskJob;import org.quartz.Scheduler;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.CommandLineRunner;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;import java.util.Date;/** * TODO * * @author 李晋科(Jinke Li) * @version TaskInitRunner.java, 2018/6/12 16:31 李晋科(Jinke Li) */@Component@Order(1)public class TaskInitRunner implements CommandLineRunner &#123; @Autowired private Scheduler scheduler; @Override public void run(String... args) throws Exception &#123; QuartzManager.setScheduler(scheduler); QuartzManager.removeAllJob(); &#125;&#125; 添加任务123456789101112131415161718192021222324252627282930package com.jianganwei.sfss.schedule;import com.jianganwei.sfss.manager.impl.QuartzManager;import org.springframework.boot.CommandLineRunner;import org.springframework.core.annotation.Order;import org.springframework.stereotype.Component;import java.util.Date;/** * * @program: SFSS * @description: 添加定时任务 * @author: jianganwei * @create: 2018-09-11 17:32 **/@Component@Order(3)public class TaskAddRunner implements CommandLineRunner &#123; @Override public void run(String... strings) throws Exception &#123; QuartzManager.addJob("oms_alarm" , AlarmTaskJob.class ,"0 30 11 * * ?",new Date()); QuartzManager.addJob("oms_invalid_contract" , InvalidContractJob.class ,"0 0 1 * * ?",new Date()); QuartzManager.addJob("oms_notice_marketing_file_upload" , NoticeMarketingFileUpLoadJob.class ,"0 */5 * * * ?",new Date()); QuartzManager.addJob("oms_contract_use_status",UpdateContractUsegeStatus.class,"0 */10 * * * ?",new Date()); QuartzManager.addJob("active_contracts_side_agreement",ActiveContractSideAgreementJob.class,"0 * */1 * * ?",new Date()); //todo 补充协议定时任务 &#125;&#125;]]></content>
      <tags>
        <tag>quartz</tag>
      </tags>
  </entry>
</search>
